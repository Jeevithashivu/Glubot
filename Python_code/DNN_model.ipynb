{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading libraries\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age (y)</th>\n",
       "      <th>Gender(1, male; 2, female)</th>\n",
       "      <th>BMI(kg/m2)</th>\n",
       "      <th>censor of diabetes at followup(1, Yes; 0, No)</th>\n",
       "      <th>smoking status(1,current smoker;2, ever smoker;3,never smoker)</th>\n",
       "      <th>drinking status(1,current drinker;2, ever drinker;3,never drinker)</th>\n",
       "      <th>family histroy of diabetes(1,Yes;0,No)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>19.3</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>23.1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>18.1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>211828</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>24.5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>211829</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>18.8</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>211830</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>17.1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>211831</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>211832</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>27.7</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>211833 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age (y)  Gender(1, male; 2, female)  BMI(kg/m2)  \\\n",
       "0            43                           2        19.3   \n",
       "1            34                           1        20.0   \n",
       "2            32                           2        20.7   \n",
       "3            59                           1        23.1   \n",
       "4            30                           2        18.1   \n",
       "...         ...                         ...         ...   \n",
       "211828       41                           1        24.5   \n",
       "211829       31                           2        18.8   \n",
       "211830       30                           2        17.1   \n",
       "211831       43                           1        25.6   \n",
       "211832       57                           1        27.7   \n",
       "\n",
       "        censor of diabetes at followup(1, Yes; 0, No)  \\\n",
       "0                                                   0   \n",
       "1                                                   0   \n",
       "2                                                   0   \n",
       "3                                                   0   \n",
       "4                                                   0   \n",
       "...                                               ...   \n",
       "211828                                              0   \n",
       "211829                                              0   \n",
       "211830                                              0   \n",
       "211831                                              0   \n",
       "211832                                              1   \n",
       "\n",
       "        smoking status(1,current smoker;2, ever smoker;3,never smoker)  \\\n",
       "0                                                     3.0                \n",
       "1                                                     NaN                \n",
       "2                                                     NaN                \n",
       "3                                                     3.0                \n",
       "4                                                     NaN                \n",
       "...                                                   ...                \n",
       "211828                                                NaN                \n",
       "211829                                                NaN                \n",
       "211830                                                NaN                \n",
       "211831                                                NaN                \n",
       "211832                                                1.0                \n",
       "\n",
       "        drinking status(1,current drinker;2, ever drinker;3,never drinker)  \\\n",
       "0                                                     3.0                    \n",
       "1                                                     NaN                    \n",
       "2                                                     NaN                    \n",
       "3                                                     3.0                    \n",
       "4                                                     NaN                    \n",
       "...                                                   ...                    \n",
       "211828                                                NaN                    \n",
       "211829                                                NaN                    \n",
       "211830                                                NaN                    \n",
       "211831                                                NaN                    \n",
       "211832                                                2.0                    \n",
       "\n",
       "        family histroy of diabetes(1,Yes;0,No)  \n",
       "0                                            1  \n",
       "1                                            0  \n",
       "2                                            0  \n",
       "3                                            0  \n",
       "4                                            0  \n",
       "...                                        ...  \n",
       "211828                                       0  \n",
       "211829                                       0  \n",
       "211830                                       0  \n",
       "211831                                       0  \n",
       "211832                                       0  \n",
       "\n",
       "[211833 rows x 7 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading data from csv file that is in same directory as python process\n",
    "col_list = [\"Age (y)\",\"Gender(1, male; 2, female)\",\"BMI(kg/m2)\",\"censor of diabetes at followup(1, Yes; 0, No)\",\"smoking status(1,current smoker;2, ever smoker;3,never smoker)\",\n",
    "            \"drinking status(1,current drinker;2, ever drinker;3,never drinker)\",\"family histroy of diabetes(1,Yes;0,No)\"]\n",
    "data1= pd.read_csv(\"RC Health Care Data-20180820.csv\",usecols=col_list)\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Outcome</th>\n",
       "      <th>smoking</th>\n",
       "      <th>drinking</th>\n",
       "      <th>family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>19.3</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>23.1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>18.1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>211828</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>24.5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>211829</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>18.8</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>211830</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>17.1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>211831</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>211832</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>27.7</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>211833 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age  Gender   BMI  Outcome  smoking  drinking  family\n",
       "0        43       2  19.3        0      3.0       3.0       1\n",
       "1        34       1  20.0        0      NaN       NaN       0\n",
       "2        32       2  20.7        0      NaN       NaN       0\n",
       "3        59       1  23.1        0      3.0       3.0       0\n",
       "4        30       2  18.1        0      NaN       NaN       0\n",
       "...     ...     ...   ...      ...      ...       ...     ...\n",
       "211828   41       1  24.5        0      NaN       NaN       0\n",
       "211829   31       2  18.8        0      NaN       NaN       0\n",
       "211830   30       2  17.1        0      NaN       NaN       0\n",
       "211831   43       1  25.6        0      NaN       NaN       0\n",
       "211832   57       1  27.7        1      1.0       2.0       0\n",
       "\n",
       "[211833 rows x 7 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# changing columns using .columns() \n",
    "data1.columns = ['Age', 'Gender', 'BMI', 'Outcome', \n",
    "                'smoking', 'drinking', 'family']\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age         False\n",
       "Gender      False\n",
       "BMI         False\n",
       "Outcome     False\n",
       "smoking      True\n",
       "drinking     True\n",
       "family      False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#returns true if the data set has null values\n",
    "data1.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age              0\n",
       "Gender           0\n",
       "BMI              0\n",
       "Outcome          0\n",
       "smoking     151603\n",
       "drinking    151603\n",
       "family           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Gives the count of all the null values present in each column\n",
    "data1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Outcome</th>\n",
       "      <th>smoking</th>\n",
       "      <th>drinking</th>\n",
       "      <th>family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>19.3</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>23.1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>22.4</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>20.3</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>24.9</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>211799</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>24.3</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>211806</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>211812</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>211826</td>\n",
       "      <td>68</td>\n",
       "      <td>2</td>\n",
       "      <td>28.4</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>211832</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>27.7</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60230 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age  Gender   BMI  Outcome  smoking  drinking  family\n",
       "0        43       2  19.3        0      3.0       3.0       1\n",
       "3        59       1  23.1        0      3.0       3.0       0\n",
       "9        31       1  22.4        0      3.0       3.0       0\n",
       "16       25       2  20.3        0      3.0       3.0       0\n",
       "19       66       1  24.9        0      1.0       3.0       0\n",
       "...     ...     ...   ...      ...      ...       ...     ...\n",
       "211799   38       1  24.3        0      2.0       3.0       0\n",
       "211806   57       1  25.1        0      1.0       3.0       0\n",
       "211812   31       2  22.9        0      3.0       3.0       0\n",
       "211826   68       2  28.4        0      3.0       3.0       0\n",
       "211832   57       1  27.7        1      1.0       2.0       0\n",
       "\n",
       "[60230 rows x 7 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop all null values\n",
    "data1=data1.dropna()\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 60230 entries, 0 to 211832\n",
      "Data columns (total 7 columns):\n",
      "Age         60230 non-null int64\n",
      "Gender      60230 non-null int64\n",
      "BMI         60230 non-null float64\n",
      "Outcome     60230 non-null int64\n",
      "smoking     60230 non-null float64\n",
      "drinking    60230 non-null float64\n",
      "family      60230 non-null int64\n",
      "dtypes: float64(3), int64(4)\n",
      "memory usage: 3.7 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Summary of datatype and count for all ths columns\n",
    "print(data1.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_class_0, count_class_1 = data1.Outcome.value_counts()\n",
    "df_class_0 = data1[data1['Outcome'] == 0]\n",
    "df_class_1 = data1[data1['Outcome'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random under-sampling:\n",
      "1    1172\n",
      "0    1172\n",
      "Name: Outcome, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#performing random under sampling to overcome the biased nature of the model\n",
    "df_class_0_under = df_class_0.sample(count_class_1)\n",
    "df_test_under = pd.concat([df_class_0_under, df_class_1], axis=0)\n",
    "print('Random under-sampling:')\n",
    "print(df_test_under.Outcome.value_counts())\n",
    "#plot that gives the count of each class\n",
    "df_test_under.Outcome.value_counts().plot(kind='bar', title='Count (target)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131087    0\n",
       "38505     0\n",
       "68678     0\n",
       "77226     0\n",
       "183355    0\n",
       "         ..\n",
       "211159    1\n",
       "211313    1\n",
       "211395    1\n",
       "211655    1\n",
       "211832    1\n",
       "Name: Outcome, Length: 2344, dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#target variable after sampling\n",
    "y_sample= df_test_under.Outcome\n",
    "#features after sampling\n",
    "X_sample=df_test_under.drop('Outcome', axis=1)\n",
    "y_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[46.   2.  23.7  3.   3.   0. ]\n",
      " [46.   1.  23.3  1.   1.   0. ]\n",
      " [31.   1.  23.5  3.   1.   0. ]\n",
      " ...\n",
      " [69.   1.  24.9  3.   3.   0. ]\n",
      " [50.   1.  23.6  3.   3.   0. ]\n",
      " [57.   1.  27.7  2.   1.   0. ]]\n"
     ]
    }
   ],
   "source": [
    "#adding features to X\n",
    "X = np.column_stack((X_sample['Age'],X_sample['Gender'],X_sample['BMI'],X_sample['drinking'],\n",
    "                    X_sample['smoking'],X_sample['family'])\n",
    "                   )\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.37313433, 1.        , 0.30916031, 1.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.37313433, 0.        , 0.29389313, 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.14925373, 0.        , 0.30152672, 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.71641791, 0.        , 0.35496183, 1.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.43283582, 0.        , 0.30534351, 1.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.53731343, 0.        , 0.46183206, 0.5       , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scaling the data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "min_max_scaler = MinMaxScaler(feature_range=(0,1))\n",
    "X = min_max_scaler.fit_transform(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1875, 6)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#splitting sampled dataset into train and test dataset\n",
    "#random_state=0 is used to get the same output as the first split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y_sample, test_size=0.20, random_state=42)\n",
    "x_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5449 - accuracy: 0.7291 - val_loss: 0.5478 - val_accuracy: 0.7399\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5019 - accuracy: 0.7685 - val_loss: 0.5128 - val_accuracy: 0.7527\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5012 - accuracy: 0.7701 - val_loss: 0.5226 - val_accuracy: 0.7633\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4805 - accuracy: 0.7760 - val_loss: 0.4863 - val_accuracy: 0.7655\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4827 - accuracy: 0.7808 - val_loss: 0.4888 - val_accuracy: 0.7783\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4754 - accuracy: 0.7787 - val_loss: 0.4996 - val_accuracy: 0.7783\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4751 - accuracy: 0.7776 - val_loss: 0.4895 - val_accuracy: 0.7697\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4808 - accuracy: 0.7792 - val_loss: 0.4882 - val_accuracy: 0.7655\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4756 - accuracy: 0.7808 - val_loss: 0.4769 - val_accuracy: 0.7783\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4773 - accuracy: 0.7733 - val_loss: 0.4860 - val_accuracy: 0.7740\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4755 - accuracy: 0.7829 - val_loss: 0.4872 - val_accuracy: 0.7783\n",
      "Epoch 12/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4726 - accuracy: 0.7915 - val_loss: 0.4847 - val_accuracy: 0.7783\n",
      "Epoch 13/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4738 - accuracy: 0.7787 - val_loss: 0.4815 - val_accuracy: 0.7761\n",
      "Epoch 14/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4666 - accuracy: 0.7819 - val_loss: 0.5462 - val_accuracy: 0.7100\n",
      "Epoch 15/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4699 - accuracy: 0.7851 - val_loss: 0.4903 - val_accuracy: 0.7740\n",
      "Epoch 16/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4696 - accuracy: 0.7851 - val_loss: 0.4883 - val_accuracy: 0.7697\n",
      "Epoch 17/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4709 - accuracy: 0.7931 - val_loss: 0.4980 - val_accuracy: 0.7527\n",
      "Epoch 18/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4672 - accuracy: 0.7797 - val_loss: 0.4899 - val_accuracy: 0.7719\n",
      "Epoch 19/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4705 - accuracy: 0.7851 - val_loss: 0.4960 - val_accuracy: 0.7612\n",
      "Epoch 20/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4663 - accuracy: 0.7872 - val_loss: 0.4843 - val_accuracy: 0.7740\n",
      "Epoch 21/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4642 - accuracy: 0.7904 - val_loss: 0.4792 - val_accuracy: 0.7761\n",
      "Epoch 22/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4653 - accuracy: 0.7877 - val_loss: 0.4834 - val_accuracy: 0.7783\n",
      "Epoch 23/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4662 - accuracy: 0.7888 - val_loss: 0.4831 - val_accuracy: 0.7761\n",
      "Epoch 24/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4668 - accuracy: 0.7877 - val_loss: 0.4886 - val_accuracy: 0.7719\n",
      "Epoch 25/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4646 - accuracy: 0.7877 - val_loss: 0.4872 - val_accuracy: 0.7761\n",
      "Epoch 26/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4631 - accuracy: 0.7867 - val_loss: 0.4869 - val_accuracy: 0.7697\n",
      "Epoch 27/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4634 - accuracy: 0.7883 - val_loss: 0.5193 - val_accuracy: 0.7612\n",
      "Epoch 28/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4629 - accuracy: 0.7936 - val_loss: 0.4891 - val_accuracy: 0.7697\n",
      "Epoch 29/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4636 - accuracy: 0.7925 - val_loss: 0.4892 - val_accuracy: 0.7804\n",
      "Epoch 30/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4675 - accuracy: 0.7835 - val_loss: 0.4859 - val_accuracy: 0.7740\n",
      "Epoch 31/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4628 - accuracy: 0.7845 - val_loss: 0.4982 - val_accuracy: 0.7612\n",
      "Epoch 32/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4620 - accuracy: 0.7920 - val_loss: 0.4922 - val_accuracy: 0.7676\n",
      "Epoch 33/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4564 - accuracy: 0.7952 - val_loss: 0.5413 - val_accuracy: 0.7761\n",
      "Epoch 34/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4643 - accuracy: 0.7883 - val_loss: 0.4777 - val_accuracy: 0.7804\n",
      "Epoch 35/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4700 - accuracy: 0.7877 - val_loss: 0.4802 - val_accuracy: 0.7783\n",
      "Epoch 36/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4609 - accuracy: 0.7936 - val_loss: 0.4946 - val_accuracy: 0.7569\n",
      "Epoch 37/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4644 - accuracy: 0.7909 - val_loss: 0.4872 - val_accuracy: 0.7761\n",
      "Epoch 38/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4618 - accuracy: 0.7877 - val_loss: 0.4943 - val_accuracy: 0.7697\n",
      "Epoch 39/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4600 - accuracy: 0.7920 - val_loss: 0.4812 - val_accuracy: 0.7761\n",
      "Epoch 40/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4669 - accuracy: 0.7856 - val_loss: 0.4846 - val_accuracy: 0.7655\n",
      "Epoch 41/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4551 - accuracy: 0.7989 - val_loss: 0.5032 - val_accuracy: 0.7783\n",
      "Epoch 42/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4567 - accuracy: 0.7952 - val_loss: 0.5003 - val_accuracy: 0.7569\n",
      "Epoch 43/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4608 - accuracy: 0.7899 - val_loss: 0.4769 - val_accuracy: 0.7804\n",
      "Epoch 44/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4586 - accuracy: 0.7899 - val_loss: 0.4920 - val_accuracy: 0.7697\n",
      "Epoch 45/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4583 - accuracy: 0.7856 - val_loss: 0.4809 - val_accuracy: 0.7825\n",
      "Epoch 46/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4566 - accuracy: 0.7936 - val_loss: 0.4842 - val_accuracy: 0.7740\n",
      "Epoch 47/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4573 - accuracy: 0.7893 - val_loss: 0.5152 - val_accuracy: 0.7655\n",
      "Epoch 48/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4580 - accuracy: 0.7925 - val_loss: 0.4878 - val_accuracy: 0.7761\n",
      "Epoch 49/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4539 - accuracy: 0.7963 - val_loss: 0.4997 - val_accuracy: 0.7740\n",
      "Epoch 50/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4562 - accuracy: 0.7973 - val_loss: 0.4848 - val_accuracy: 0.7804\n",
      "Epoch 51/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4587 - accuracy: 0.7915 - val_loss: 0.4939 - val_accuracy: 0.7740\n",
      "Epoch 52/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4547 - accuracy: 0.7957 - val_loss: 0.4983 - val_accuracy: 0.7697\n",
      "Epoch 53/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4529 - accuracy: 0.8000 - val_loss: 0.4967 - val_accuracy: 0.7527\n",
      "Epoch 54/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4520 - accuracy: 0.7909 - val_loss: 0.5058 - val_accuracy: 0.7719\n",
      "Epoch 55/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4564 - accuracy: 0.7915 - val_loss: 0.4889 - val_accuracy: 0.7697\n",
      "Epoch 56/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4525 - accuracy: 0.7968 - val_loss: 0.5685 - val_accuracy: 0.7719\n",
      "Epoch 57/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4537 - accuracy: 0.7947 - val_loss: 0.4910 - val_accuracy: 0.7761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4518 - accuracy: 0.7941 - val_loss: 0.4855 - val_accuracy: 0.7719\n",
      "Epoch 59/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4541 - accuracy: 0.7952 - val_loss: 0.5034 - val_accuracy: 0.7676\n",
      "Epoch 60/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4538 - accuracy: 0.7968 - val_loss: 0.4928 - val_accuracy: 0.7719\n",
      "Epoch 61/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4474 - accuracy: 0.8016 - val_loss: 0.5107 - val_accuracy: 0.7761\n",
      "Epoch 62/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4517 - accuracy: 0.7952 - val_loss: 0.4982 - val_accuracy: 0.7676\n",
      "Epoch 63/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4547 - accuracy: 0.7963 - val_loss: 0.4884 - val_accuracy: 0.7719\n",
      "Epoch 64/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4483 - accuracy: 0.7963 - val_loss: 0.5139 - val_accuracy: 0.7719\n",
      "Epoch 65/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4490 - accuracy: 0.7973 - val_loss: 0.4962 - val_accuracy: 0.7719\n",
      "Epoch 66/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4561 - accuracy: 0.7952 - val_loss: 0.4852 - val_accuracy: 0.7804\n",
      "Epoch 67/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4446 - accuracy: 0.7968 - val_loss: 0.4923 - val_accuracy: 0.7783\n",
      "Epoch 68/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4501 - accuracy: 0.7941 - val_loss: 0.4969 - val_accuracy: 0.7804\n",
      "Epoch 69/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4462 - accuracy: 0.7995 - val_loss: 0.5066 - val_accuracy: 0.7740\n",
      "Epoch 70/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4469 - accuracy: 0.7995 - val_loss: 0.4962 - val_accuracy: 0.7761\n",
      "Epoch 71/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4467 - accuracy: 0.7925 - val_loss: 0.4944 - val_accuracy: 0.7676\n",
      "Epoch 72/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4484 - accuracy: 0.7963 - val_loss: 0.4922 - val_accuracy: 0.7697\n",
      "Epoch 73/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4461 - accuracy: 0.8027 - val_loss: 0.4976 - val_accuracy: 0.7719\n",
      "Epoch 74/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4450 - accuracy: 0.7957 - val_loss: 0.5020 - val_accuracy: 0.7846\n",
      "Epoch 75/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4514 - accuracy: 0.7947 - val_loss: 0.5004 - val_accuracy: 0.7719\n",
      "Epoch 76/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4432 - accuracy: 0.8005 - val_loss: 0.5045 - val_accuracy: 0.7719\n",
      "Epoch 77/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4439 - accuracy: 0.7995 - val_loss: 0.5312 - val_accuracy: 0.7783\n",
      "Epoch 78/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4473 - accuracy: 0.7931 - val_loss: 0.5036 - val_accuracy: 0.7719\n",
      "Epoch 79/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4619 - accuracy: 0.7904 - val_loss: 0.4973 - val_accuracy: 0.7740\n",
      "Epoch 80/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4477 - accuracy: 0.7947 - val_loss: 0.4955 - val_accuracy: 0.7761\n",
      "Epoch 81/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4414 - accuracy: 0.8011 - val_loss: 0.5059 - val_accuracy: 0.7676\n",
      "Epoch 82/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4502 - accuracy: 0.7947 - val_loss: 0.4971 - val_accuracy: 0.7719\n",
      "Epoch 83/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4472 - accuracy: 0.8011 - val_loss: 0.4924 - val_accuracy: 0.7612\n",
      "Epoch 84/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4406 - accuracy: 0.8016 - val_loss: 0.5004 - val_accuracy: 0.7676\n",
      "Epoch 85/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4421 - accuracy: 0.7984 - val_loss: 0.5285 - val_accuracy: 0.7783\n",
      "Epoch 86/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4437 - accuracy: 0.7957 - val_loss: 0.5188 - val_accuracy: 0.7505\n",
      "Epoch 87/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4418 - accuracy: 0.7995 - val_loss: 0.5227 - val_accuracy: 0.7889\n",
      "Epoch 88/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4406 - accuracy: 0.8059 - val_loss: 0.5246 - val_accuracy: 0.7719\n",
      "Epoch 89/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4419 - accuracy: 0.7995 - val_loss: 0.5331 - val_accuracy: 0.7697\n",
      "Epoch 90/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4406 - accuracy: 0.8021 - val_loss: 0.5083 - val_accuracy: 0.7697\n",
      "Epoch 91/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4433 - accuracy: 0.8005 - val_loss: 0.5172 - val_accuracy: 0.7719\n",
      "Epoch 92/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4544 - accuracy: 0.7888 - val_loss: 0.5105 - val_accuracy: 0.7569\n",
      "Epoch 93/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4400 - accuracy: 0.8011 - val_loss: 0.5510 - val_accuracy: 0.7655\n",
      "Epoch 94/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4511 - accuracy: 0.8037 - val_loss: 0.5212 - val_accuracy: 0.7484\n",
      "Epoch 95/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4415 - accuracy: 0.8037 - val_loss: 0.5065 - val_accuracy: 0.7655\n",
      "Epoch 96/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4405 - accuracy: 0.8000 - val_loss: 0.5168 - val_accuracy: 0.7569\n",
      "Epoch 97/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4387 - accuracy: 0.8005 - val_loss: 0.5052 - val_accuracy: 0.7676\n",
      "Epoch 98/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4411 - accuracy: 0.8000 - val_loss: 0.5351 - val_accuracy: 0.7719\n",
      "Epoch 99/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4388 - accuracy: 0.8059 - val_loss: 0.5499 - val_accuracy: 0.7761\n",
      "Epoch 100/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4376 - accuracy: 0.8080 - val_loss: 0.5561 - val_accuracy: 0.7719\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d078ab4f88>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DNN model\n",
    "model = Sequential()\n",
    "model.add(Dense(500, input_dim=6, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(x_train,y_train, epochs=100, batch_size=5, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_class_nn_1 = model.predict_classes(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_class_nn_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.772\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score# Print model performance and plot the roc curve\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[158  76]\n",
      " [ 31 204]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7718550106609808"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred_class_nn_1)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred_class_nn_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.68      0.75       234\n",
      "           1       0.73      0.87      0.79       235\n",
      "\n",
      "    accuracy                           0.77       469\n",
      "   macro avg       0.78      0.77      0.77       469\n",
      "weighted avg       0.78      0.77      0.77       469\n",
      "\n",
      "[[158  76]\n",
      " [ 31 204]]\n"
     ]
    }
   ],
   "source": [
    "#classification report for precision, recall and f1-score for both class\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test,y_pred_class_nn_1, labels=[0,1]))\n",
    "confusion = metrics.confusion_matrix(y_test, y_pred_class_nn_1)\n",
    "print(confusion)\n",
    "#[row, column]\n",
    "TP = confusion[1, 1]\n",
    "TN = confusion[0, 0]\n",
    "FP = confusion[0, 1]\n",
    "FN = confusion[1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7718550106609808\n",
      "0.7718550106609808\n"
     ]
    }
   ],
   "source": [
    "# use float to perform true division, not integer division\n",
    "print((TP + TN) / float(TP + TN + FP + FN))\n",
    "print(metrics.accuracy_score(y_test, y_pred_class_nn_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2281449893390192\n",
      "0.22814498933901917\n"
     ]
    }
   ],
   "source": [
    "\n",
    "classification_error = (FP + FN) / float(TP + TN + FP + FN)\n",
    "\n",
    "print(classification_error)\n",
    "\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred_class_nn_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8680851063829788\n",
      "0.8680851063829788\n"
     ]
    }
   ],
   "source": [
    "sensitivity = TP / float(FN + TP)\n",
    "\n",
    "print(sensitivity)\n",
    "print(metrics.recall_score(y_test, y_pred_class_nn_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6752136752136753\n"
     ]
    }
   ],
   "source": [
    "specificity = TN / (TN + FP)\n",
    "\n",
    "print(specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8680851063829788\n"
     ]
    }
   ],
   "source": [
    "recall = TP / float(TP + FN)\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3247863247863248\n",
      "0.32478632478632474\n"
     ]
    }
   ],
   "source": [
    "false_positive_rate = FP / float(TN + FP)\n",
    "\n",
    "print(false_positive_rate)\n",
    "print(1 - specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7285714285714285\n",
      "0.7285714285714285\n"
     ]
    }
   ],
   "source": [
    "precision = TP / float(TP + FP)\n",
    "\n",
    "print(precision)\n",
    "print(metrics.precision_score(y_test, y_pred_class_nn_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7922330097087379\n"
     ]
    }
   ],
   "source": [
    "f1score= 2*(recall * precision) / (recall + precision)\n",
    "print(f1score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_133 (Dense)            (None, 500)               3500      \n",
      "_________________________________________________________________\n",
      "dense_134 (Dense)            (None, 100)               50100     \n",
      "_________________________________________________________________\n",
      "dense_135 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_136 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_137 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_138 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_139 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 94,101\n",
      "Trainable params: 94,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5462 - accuracy: 0.7333 - val_loss: 0.5060 - val_accuracy: 0.7484\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4997 - accuracy: 0.7659 - val_loss: 0.4926 - val_accuracy: 0.7591\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4905 - accuracy: 0.7813 - val_loss: 0.4803 - val_accuracy: 0.7825\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4837 - accuracy: 0.7723 - val_loss: 0.4956 - val_accuracy: 0.7783\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4826 - accuracy: 0.7749 - val_loss: 0.4895 - val_accuracy: 0.7633\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4859 - accuracy: 0.7733 - val_loss: 0.5117 - val_accuracy: 0.7356\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4779 - accuracy: 0.7803 - val_loss: 0.5143 - val_accuracy: 0.7591\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4749 - accuracy: 0.7819 - val_loss: 0.4875 - val_accuracy: 0.7783\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4764 - accuracy: 0.7728 - val_loss: 0.4950 - val_accuracy: 0.7740\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4744 - accuracy: 0.7856 - val_loss: 0.5042 - val_accuracy: 0.7591\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4787 - accuracy: 0.7835 - val_loss: 0.4889 - val_accuracy: 0.7740\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4710 - accuracy: 0.7787 - val_loss: 0.4846 - val_accuracy: 0.7761\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4697 - accuracy: 0.7851 - val_loss: 0.4806 - val_accuracy: 0.7697\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4693 - accuracy: 0.7803 - val_loss: 0.4818 - val_accuracy: 0.7740\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4731 - accuracy: 0.7781 - val_loss: 0.4999 - val_accuracy: 0.7676\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4675 - accuracy: 0.7819 - val_loss: 0.4873 - val_accuracy: 0.7761\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4702 - accuracy: 0.7851 - val_loss: 0.4970 - val_accuracy: 0.7655\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4711 - accuracy: 0.7797 - val_loss: 0.4869 - val_accuracy: 0.7783\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4691 - accuracy: 0.7845 - val_loss: 0.4780 - val_accuracy: 0.7783\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4634 - accuracy: 0.7899 - val_loss: 0.4886 - val_accuracy: 0.7740\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4721 - accuracy: 0.7840 - val_loss: 0.4981 - val_accuracy: 0.7655\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4677 - accuracy: 0.7861 - val_loss: 0.5055 - val_accuracy: 0.7548\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4674 - accuracy: 0.7813 - val_loss: 0.4895 - val_accuracy: 0.7804\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4676 - accuracy: 0.7861 - val_loss: 0.4823 - val_accuracy: 0.7804\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4668 - accuracy: 0.7872 - val_loss: 0.4849 - val_accuracy: 0.7697\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4647 - accuracy: 0.7851 - val_loss: 0.4875 - val_accuracy: 0.7719\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4682 - accuracy: 0.7856 - val_loss: 0.4868 - val_accuracy: 0.7740\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4668 - accuracy: 0.7904 - val_loss: 0.4814 - val_accuracy: 0.7761\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4623 - accuracy: 0.7867 - val_loss: 0.4926 - val_accuracy: 0.7740\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4598 - accuracy: 0.7979 - val_loss: 0.4893 - val_accuracy: 0.7633\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4653 - accuracy: 0.7893 - val_loss: 0.4809 - val_accuracy: 0.7761\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4600 - accuracy: 0.7867 - val_loss: 0.4900 - val_accuracy: 0.7697\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4630 - accuracy: 0.7952 - val_loss: 0.4845 - val_accuracy: 0.7783\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4595 - accuracy: 0.7893 - val_loss: 0.4902 - val_accuracy: 0.7676\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4654 - accuracy: 0.7861 - val_loss: 0.4937 - val_accuracy: 0.7719\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4601 - accuracy: 0.7936 - val_loss: 0.4881 - val_accuracy: 0.7761\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4616 - accuracy: 0.7936 - val_loss: 0.4799 - val_accuracy: 0.7825\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4578 - accuracy: 0.7893 - val_loss: 0.4847 - val_accuracy: 0.7825\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4616 - accuracy: 0.7947 - val_loss: 0.4772 - val_accuracy: 0.7825\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4563 - accuracy: 0.7867 - val_loss: 0.4892 - val_accuracy: 0.7697\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4615 - accuracy: 0.7861 - val_loss: 0.4886 - val_accuracy: 0.7761\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4558 - accuracy: 0.7984 - val_loss: 0.4963 - val_accuracy: 0.7740\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4565 - accuracy: 0.7899 - val_loss: 0.5018 - val_accuracy: 0.7655\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4606 - accuracy: 0.7941 - val_loss: 0.5027 - val_accuracy: 0.7719\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4558 - accuracy: 0.7915 - val_loss: 0.4919 - val_accuracy: 0.7697\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4524 - accuracy: 0.7947 - val_loss: 0.4827 - val_accuracy: 0.7804\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4557 - accuracy: 0.7941 - val_loss: 0.5018 - val_accuracy: 0.7740\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4572 - accuracy: 0.7952 - val_loss: 0.5030 - val_accuracy: 0.7676\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4554 - accuracy: 0.7963 - val_loss: 0.4898 - val_accuracy: 0.7655\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4533 - accuracy: 0.7931 - val_loss: 0.4893 - val_accuracy: 0.7697\n",
      "accuracy: 76.97%\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_140 (Dense)            (None, 500)               3500      \n",
      "_________________________________________________________________\n",
      "dense_141 (Dense)            (None, 100)               50100     \n",
      "_________________________________________________________________\n",
      "dense_142 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_143 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_144 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_145 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_146 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 94,101\n",
      "Trainable params: 94,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5508 - accuracy: 0.7328 - val_loss: 0.5057 - val_accuracy: 0.7548\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5015 - accuracy: 0.7653 - val_loss: 0.4943 - val_accuracy: 0.7591\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4917 - accuracy: 0.7696 - val_loss: 0.5092 - val_accuracy: 0.7655\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4828 - accuracy: 0.7813 - val_loss: 0.4823 - val_accuracy: 0.7825\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4839 - accuracy: 0.7797 - val_loss: 0.4923 - val_accuracy: 0.7783\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4801 - accuracy: 0.7824 - val_loss: 0.4846 - val_accuracy: 0.7804\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4801 - accuracy: 0.7813 - val_loss: 0.4803 - val_accuracy: 0.7783\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4802 - accuracy: 0.7685 - val_loss: 0.4910 - val_accuracy: 0.7655\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4771 - accuracy: 0.7883 - val_loss: 0.5408 - val_accuracy: 0.7612\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4770 - accuracy: 0.7776 - val_loss: 0.4837 - val_accuracy: 0.7740\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4774 - accuracy: 0.7835 - val_loss: 0.4879 - val_accuracy: 0.7697\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4695 - accuracy: 0.7851 - val_loss: 0.4919 - val_accuracy: 0.7548\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4708 - accuracy: 0.7808 - val_loss: 0.4956 - val_accuracy: 0.7761\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4754 - accuracy: 0.7776 - val_loss: 0.5028 - val_accuracy: 0.7569\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.4770 - accuracy: 0.78 - 1s 2ms/step - loss: 0.4732 - accuracy: 0.7835 - val_loss: 0.4980 - val_accuracy: 0.7804\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4736 - accuracy: 0.7909 - val_loss: 0.4837 - val_accuracy: 0.7783\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4659 - accuracy: 0.7877 - val_loss: 0.4889 - val_accuracy: 0.7761\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4684 - accuracy: 0.7840 - val_loss: 0.4837 - val_accuracy: 0.7804\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4678 - accuracy: 0.7851 - val_loss: 0.4875 - val_accuracy: 0.7591\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4669 - accuracy: 0.7904 - val_loss: 0.4861 - val_accuracy: 0.7697\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4625 - accuracy: 0.7941 - val_loss: 0.5108 - val_accuracy: 0.7676\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4685 - accuracy: 0.7872 - val_loss: 0.4947 - val_accuracy: 0.7761\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4646 - accuracy: 0.7888 - val_loss: 0.4788 - val_accuracy: 0.7761\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4664 - accuracy: 0.7861 - val_loss: 0.4966 - val_accuracy: 0.7591\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4663 - accuracy: 0.7872 - val_loss: 0.4807 - val_accuracy: 0.7783\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4684 - accuracy: 0.7808 - val_loss: 0.4801 - val_accuracy: 0.7804\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4678 - accuracy: 0.7877 - val_loss: 0.4856 - val_accuracy: 0.7761\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4604 - accuracy: 0.7899 - val_loss: 0.4852 - val_accuracy: 0.7740\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4646 - accuracy: 0.7893 - val_loss: 0.4820 - val_accuracy: 0.7804\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4670 - accuracy: 0.7968 - val_loss: 0.4857 - val_accuracy: 0.7804\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4629 - accuracy: 0.7941 - val_loss: 0.4975 - val_accuracy: 0.7825\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4626 - accuracy: 0.7925 - val_loss: 0.4906 - val_accuracy: 0.7740\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4627 - accuracy: 0.7851 - val_loss: 0.4936 - val_accuracy: 0.7740\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4640 - accuracy: 0.7856 - val_loss: 0.4889 - val_accuracy: 0.7740\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4612 - accuracy: 0.7909 - val_loss: 0.4804 - val_accuracy: 0.7783\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4622 - accuracy: 0.7920 - val_loss: 0.4823 - val_accuracy: 0.7761\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4597 - accuracy: 0.7883 - val_loss: 0.4833 - val_accuracy: 0.7761\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4590 - accuracy: 0.7904 - val_loss: 0.4837 - val_accuracy: 0.7740\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4586 - accuracy: 0.7888 - val_loss: 0.4896 - val_accuracy: 0.7740\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4613 - accuracy: 0.7941 - val_loss: 0.4809 - val_accuracy: 0.7761\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4618 - accuracy: 0.7829 - val_loss: 0.5002 - val_accuracy: 0.7676\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4584 - accuracy: 0.7952 - val_loss: 0.4877 - val_accuracy: 0.7740\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4542 - accuracy: 0.7915 - val_loss: 0.4996 - val_accuracy: 0.7591\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4595 - accuracy: 0.7920 - val_loss: 0.5060 - val_accuracy: 0.7740\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4603 - accuracy: 0.7904 - val_loss: 0.5356 - val_accuracy: 0.7761\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4624 - accuracy: 0.7936 - val_loss: 0.4881 - val_accuracy: 0.7740\n",
      "Epoch 47/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4561 - accuracy: 0.7995 - val_loss: 0.4846 - val_accuracy: 0.7783\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4609 - accuracy: 0.7877 - val_loss: 0.5170 - val_accuracy: 0.7612\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4583 - accuracy: 0.7819 - val_loss: 0.4864 - val_accuracy: 0.7697\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4553 - accuracy: 0.7899 - val_loss: 0.4839 - val_accuracy: 0.7804\n",
      "accuracy: 78.04%\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_147 (Dense)            (None, 500)               3500      \n",
      "_________________________________________________________________\n",
      "dense_148 (Dense)            (None, 100)               50100     \n",
      "_________________________________________________________________\n",
      "dense_149 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_150 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_151 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_152 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_153 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 94,101\n",
      "Trainable params: 94,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5407 - accuracy: 0.7328 - val_loss: 0.5001 - val_accuracy: 0.7591\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4965 - accuracy: 0.7728 - val_loss: 0.4993 - val_accuracy: 0.7697\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4919 - accuracy: 0.7803 - val_loss: 0.4862 - val_accuracy: 0.7868\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4906 - accuracy: 0.7792 - val_loss: 0.4920 - val_accuracy: 0.7719\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4835 - accuracy: 0.7808 - val_loss: 0.5242 - val_accuracy: 0.7441\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4805 - accuracy: 0.7851 - val_loss: 0.4947 - val_accuracy: 0.7633\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4757 - accuracy: 0.7845 - val_loss: 0.5032 - val_accuracy: 0.7612\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4831 - accuracy: 0.7792 - val_loss: 0.4912 - val_accuracy: 0.7783\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4738 - accuracy: 0.7813 - val_loss: 0.5292 - val_accuracy: 0.7740\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4802 - accuracy: 0.7797 - val_loss: 0.4934 - val_accuracy: 0.7761\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4695 - accuracy: 0.7819 - val_loss: 0.5079 - val_accuracy: 0.7612\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4763 - accuracy: 0.7829 - val_loss: 0.5019 - val_accuracy: 0.7633\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4719 - accuracy: 0.7872 - val_loss: 0.4914 - val_accuracy: 0.7612\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4717 - accuracy: 0.7877 - val_loss: 0.4804 - val_accuracy: 0.7719\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4703 - accuracy: 0.7797 - val_loss: 0.5105 - val_accuracy: 0.7655\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4689 - accuracy: 0.7867 - val_loss: 0.5029 - val_accuracy: 0.7804\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4711 - accuracy: 0.7792 - val_loss: 0.4877 - val_accuracy: 0.7719\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4681 - accuracy: 0.7856 - val_loss: 0.4823 - val_accuracy: 0.7804\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4664 - accuracy: 0.7845 - val_loss: 0.4871 - val_accuracy: 0.7740\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4696 - accuracy: 0.7856 - val_loss: 0.4994 - val_accuracy: 0.7783\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4671 - accuracy: 0.7877 - val_loss: 0.4889 - val_accuracy: 0.7719\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4740 - accuracy: 0.7845 - val_loss: 0.4976 - val_accuracy: 0.7719\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4653 - accuracy: 0.7835 - val_loss: 0.5254 - val_accuracy: 0.7463\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4661 - accuracy: 0.7781 - val_loss: 0.4873 - val_accuracy: 0.7761\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4684 - accuracy: 0.7765 - val_loss: 0.4947 - val_accuracy: 0.7612\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4655 - accuracy: 0.7861 - val_loss: 0.4917 - val_accuracy: 0.7697\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4654 - accuracy: 0.7893 - val_loss: 0.4824 - val_accuracy: 0.7719\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4618 - accuracy: 0.7899 - val_loss: 0.4861 - val_accuracy: 0.7740\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4626 - accuracy: 0.7888 - val_loss: 0.4834 - val_accuracy: 0.7740\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4622 - accuracy: 0.7893 - val_loss: 0.4828 - val_accuracy: 0.7740\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4626 - accuracy: 0.7867 - val_loss: 0.4798 - val_accuracy: 0.7804\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4621 - accuracy: 0.7867 - val_loss: 0.4835 - val_accuracy: 0.7761\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4612 - accuracy: 0.7941 - val_loss: 0.4857 - val_accuracy: 0.7719\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4624 - accuracy: 0.7867 - val_loss: 0.4840 - val_accuracy: 0.7740\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4644 - accuracy: 0.7909 - val_loss: 0.4783 - val_accuracy: 0.7719\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4629 - accuracy: 0.7883 - val_loss: 0.4828 - val_accuracy: 0.7825\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4611 - accuracy: 0.7877 - val_loss: 0.4963 - val_accuracy: 0.7761\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4610 - accuracy: 0.7888 - val_loss: 0.4839 - val_accuracy: 0.7761\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4590 - accuracy: 0.7877 - val_loss: 0.4879 - val_accuracy: 0.7655\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4640 - accuracy: 0.7893 - val_loss: 0.4831 - val_accuracy: 0.7783\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4592 - accuracy: 0.7899 - val_loss: 0.4910 - val_accuracy: 0.7697\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4553 - accuracy: 0.7941 - val_loss: 0.4811 - val_accuracy: 0.7825\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4592 - accuracy: 0.7904 - val_loss: 0.4958 - val_accuracy: 0.7783\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4612 - accuracy: 0.7909 - val_loss: 0.4800 - val_accuracy: 0.7761\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4578 - accuracy: 0.7963 - val_loss: 0.4927 - val_accuracy: 0.7825\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4568 - accuracy: 0.7936 - val_loss: 0.4818 - val_accuracy: 0.7719\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4601 - accuracy: 0.7904 - val_loss: 0.4816 - val_accuracy: 0.7868\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4542 - accuracy: 0.7920 - val_loss: 0.5105 - val_accuracy: 0.7740\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4548 - accuracy: 0.7941 - val_loss: 0.4887 - val_accuracy: 0.7825\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4542 - accuracy: 0.7941 - val_loss: 0.4815 - val_accuracy: 0.7783\n",
      "accuracy: 77.83%\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_154 (Dense)            (None, 500)               3500      \n",
      "_________________________________________________________________\n",
      "dense_155 (Dense)            (None, 100)               50100     \n",
      "_________________________________________________________________\n",
      "dense_156 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_157 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_158 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_159 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_160 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 94,101\n",
      "Trainable params: 94,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5414 - accuracy: 0.7227 - val_loss: 0.5539 - val_accuracy: 0.7612\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5110 - accuracy: 0.7579 - val_loss: 0.5565 - val_accuracy: 0.7249\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4881 - accuracy: 0.7733 - val_loss: 0.4988 - val_accuracy: 0.7719\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4816 - accuracy: 0.7829 - val_loss: 0.4807 - val_accuracy: 0.7804\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4818 - accuracy: 0.7797 - val_loss: 0.4899 - val_accuracy: 0.7655\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4741 - accuracy: 0.7781 - val_loss: 0.4896 - val_accuracy: 0.7910\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4786 - accuracy: 0.7787 - val_loss: 0.4821 - val_accuracy: 0.7825\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4823 - accuracy: 0.7755 - val_loss: 0.4829 - val_accuracy: 0.7825\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4794 - accuracy: 0.7787 - val_loss: 0.4890 - val_accuracy: 0.7783\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4832 - accuracy: 0.7776 - val_loss: 0.4985 - val_accuracy: 0.7740\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4768 - accuracy: 0.7797 - val_loss: 0.4852 - val_accuracy: 0.7697\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4748 - accuracy: 0.7787 - val_loss: 0.4959 - val_accuracy: 0.7676\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4663 - accuracy: 0.7819 - val_loss: 0.4951 - val_accuracy: 0.7569\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4674 - accuracy: 0.7813 - val_loss: 0.4784 - val_accuracy: 0.7740\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4689 - accuracy: 0.7813 - val_loss: 0.4944 - val_accuracy: 0.7761\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4691 - accuracy: 0.7819 - val_loss: 0.4863 - val_accuracy: 0.7719\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4715 - accuracy: 0.7872 - val_loss: 0.4853 - val_accuracy: 0.7804\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4717 - accuracy: 0.7792 - val_loss: 0.4813 - val_accuracy: 0.7761\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4717 - accuracy: 0.7792 - val_loss: 0.5045 - val_accuracy: 0.7783\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4696 - accuracy: 0.7840 - val_loss: 0.4820 - val_accuracy: 0.7846\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4716 - accuracy: 0.7835 - val_loss: 0.4876 - val_accuracy: 0.7740\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4643 - accuracy: 0.7920 - val_loss: 0.4854 - val_accuracy: 0.7825\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4712 - accuracy: 0.7845 - val_loss: 0.4816 - val_accuracy: 0.7804\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4658 - accuracy: 0.7840 - val_loss: 0.4758 - val_accuracy: 0.7804\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4672 - accuracy: 0.7888 - val_loss: 0.5010 - val_accuracy: 0.7783\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4656 - accuracy: 0.7851 - val_loss: 0.4997 - val_accuracy: 0.7740\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4674 - accuracy: 0.7856 - val_loss: 0.4831 - val_accuracy: 0.7740\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4617 - accuracy: 0.7931 - val_loss: 0.4858 - val_accuracy: 0.7804\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4674 - accuracy: 0.7909 - val_loss: 0.4808 - val_accuracy: 0.7804\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4657 - accuracy: 0.7883 - val_loss: 0.4823 - val_accuracy: 0.7804\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4594 - accuracy: 0.7920 - val_loss: 0.4882 - val_accuracy: 0.7761\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4662 - accuracy: 0.7883 - val_loss: 0.4836 - val_accuracy: 0.7761\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4680 - accuracy: 0.7883 - val_loss: 0.4944 - val_accuracy: 0.7676\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4638 - accuracy: 0.7899 - val_loss: 0.4859 - val_accuracy: 0.7740\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4630 - accuracy: 0.7856 - val_loss: 0.4833 - val_accuracy: 0.7783\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4630 - accuracy: 0.7947 - val_loss: 0.4854 - val_accuracy: 0.7761\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4591 - accuracy: 0.7947 - val_loss: 0.4880 - val_accuracy: 0.7655\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4600 - accuracy: 0.7941 - val_loss: 0.4919 - val_accuracy: 0.7761\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4631 - accuracy: 0.7883 - val_loss: 0.4896 - val_accuracy: 0.7783\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4661 - accuracy: 0.7861 - val_loss: 0.4816 - val_accuracy: 0.7783\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4581 - accuracy: 0.7904 - val_loss: 0.4955 - val_accuracy: 0.7719\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4556 - accuracy: 0.7968 - val_loss: 0.5177 - val_accuracy: 0.7740\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4589 - accuracy: 0.7904 - val_loss: 0.4893 - val_accuracy: 0.7719\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4589 - accuracy: 0.7904 - val_loss: 0.5015 - val_accuracy: 0.7804\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4612 - accuracy: 0.7888 - val_loss: 0.4846 - val_accuracy: 0.7697\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4563 - accuracy: 0.7925 - val_loss: 0.4959 - val_accuracy: 0.7783\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4551 - accuracy: 0.7947 - val_loss: 0.4907 - val_accuracy: 0.7761\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4642 - accuracy: 0.7845 - val_loss: 0.4861 - val_accuracy: 0.7761\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4574 - accuracy: 0.7947 - val_loss: 0.4808 - val_accuracy: 0.7740\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4575 - accuracy: 0.7920 - val_loss: 0.4962 - val_accuracy: 0.7740\n",
      "accuracy: 77.40%\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_161 (Dense)            (None, 500)               3500      \n",
      "_________________________________________________________________\n",
      "dense_162 (Dense)            (None, 100)               50100     \n",
      "_________________________________________________________________\n",
      "dense_163 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_164 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_165 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_166 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_167 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 94,101\n",
      "Trainable params: 94,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5644 - accuracy: 0.7152 - val_loss: 0.5111 - val_accuracy: 0.7591\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5021 - accuracy: 0.7669 - val_loss: 0.5009 - val_accuracy: 0.7548\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4973 - accuracy: 0.7781 - val_loss: 0.5421 - val_accuracy: 0.7655\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4853 - accuracy: 0.7739 - val_loss: 0.4814 - val_accuracy: 0.7740\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4845 - accuracy: 0.7813 - val_loss: 0.5205 - val_accuracy: 0.7420\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4799 - accuracy: 0.7787 - val_loss: 0.4836 - val_accuracy: 0.7740\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4822 - accuracy: 0.7803 - val_loss: 0.5395 - val_accuracy: 0.7292\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4780 - accuracy: 0.7765 - val_loss: 0.4829 - val_accuracy: 0.7804\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4735 - accuracy: 0.7845 - val_loss: 0.5100 - val_accuracy: 0.7740\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4793 - accuracy: 0.7819 - val_loss: 0.5123 - val_accuracy: 0.7591\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4735 - accuracy: 0.7813 - val_loss: 0.5347 - val_accuracy: 0.7249\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4737 - accuracy: 0.7776 - val_loss: 0.4980 - val_accuracy: 0.7740\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4664 - accuracy: 0.7851 - val_loss: 0.4808 - val_accuracy: 0.7783\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4696 - accuracy: 0.7845 - val_loss: 0.5005 - val_accuracy: 0.7441\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4670 - accuracy: 0.7840 - val_loss: 0.4860 - val_accuracy: 0.7761\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4742 - accuracy: 0.7861 - val_loss: 0.4993 - val_accuracy: 0.7868\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4655 - accuracy: 0.7888 - val_loss: 0.4879 - val_accuracy: 0.7761\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4703 - accuracy: 0.7840 - val_loss: 0.4826 - val_accuracy: 0.7740\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4684 - accuracy: 0.7899 - val_loss: 0.4805 - val_accuracy: 0.7740\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4647 - accuracy: 0.7829 - val_loss: 0.4891 - val_accuracy: 0.7761\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4642 - accuracy: 0.7883 - val_loss: 0.4852 - val_accuracy: 0.7719\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4660 - accuracy: 0.7851 - val_loss: 0.4801 - val_accuracy: 0.7825\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4658 - accuracy: 0.7803 - val_loss: 0.4803 - val_accuracy: 0.7825\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4653 - accuracy: 0.7840 - val_loss: 0.4868 - val_accuracy: 0.7761\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4665 - accuracy: 0.7877 - val_loss: 0.4806 - val_accuracy: 0.7825\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4598 - accuracy: 0.7856 - val_loss: 0.5009 - val_accuracy: 0.7761\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4669 - accuracy: 0.7968 - val_loss: 0.4885 - val_accuracy: 0.7719\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4638 - accuracy: 0.7883 - val_loss: 0.4925 - val_accuracy: 0.7719\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4667 - accuracy: 0.7893 - val_loss: 0.4809 - val_accuracy: 0.7761\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4600 - accuracy: 0.7915 - val_loss: 0.4805 - val_accuracy: 0.7846\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4657 - accuracy: 0.7840 - val_loss: 0.4834 - val_accuracy: 0.7740\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4632 - accuracy: 0.7936 - val_loss: 0.4843 - val_accuracy: 0.7783\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4625 - accuracy: 0.7920 - val_loss: 0.4837 - val_accuracy: 0.7825\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4633 - accuracy: 0.7904 - val_loss: 0.4811 - val_accuracy: 0.7761\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4577 - accuracy: 0.7947 - val_loss: 0.4869 - val_accuracy: 0.7761\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4620 - accuracy: 0.7845 - val_loss: 0.4964 - val_accuracy: 0.7783\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4643 - accuracy: 0.7840 - val_loss: 0.4925 - val_accuracy: 0.7846\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4650 - accuracy: 0.7904 - val_loss: 0.5017 - val_accuracy: 0.7719\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4656 - accuracy: 0.7851 - val_loss: 0.4914 - val_accuracy: 0.7740\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4581 - accuracy: 0.7893 - val_loss: 0.5128 - val_accuracy: 0.7697\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4573 - accuracy: 0.7915 - val_loss: 0.4808 - val_accuracy: 0.7761\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4589 - accuracy: 0.7904 - val_loss: 0.4879 - val_accuracy: 0.7804\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4589 - accuracy: 0.7888 - val_loss: 0.4875 - val_accuracy: 0.7761\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4538 - accuracy: 0.7920 - val_loss: 0.4876 - val_accuracy: 0.7740\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4570 - accuracy: 0.7899 - val_loss: 0.4995 - val_accuracy: 0.7484\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4555 - accuracy: 0.7925 - val_loss: 0.4984 - val_accuracy: 0.7676\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4566 - accuracy: 0.7893 - val_loss: 0.4952 - val_accuracy: 0.7740\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4571 - accuracy: 0.7931 - val_loss: 0.4929 - val_accuracy: 0.7612\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4643 - accuracy: 0.7851 - val_loss: 0.5069 - val_accuracy: 0.7633\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4545 - accuracy: 0.7872 - val_loss: 0.4976 - val_accuracy: 0.7612\n",
      "accuracy: 76.12%\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_168 (Dense)            (None, 500)               3500      \n",
      "_________________________________________________________________\n",
      "dense_169 (Dense)            (None, 100)               50100     \n",
      "_________________________________________________________________\n",
      "dense_170 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_171 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_172 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_173 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_174 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 94,101\n",
      "Trainable params: 94,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5398 - accuracy: 0.7312 - val_loss: 0.5032 - val_accuracy: 0.7655\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4967 - accuracy: 0.7728 - val_loss: 0.4929 - val_accuracy: 0.7655\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4974 - accuracy: 0.7749 - val_loss: 0.5304 - val_accuracy: 0.7377\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4887 - accuracy: 0.7744 - val_loss: 0.4863 - val_accuracy: 0.7740\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4893 - accuracy: 0.7808 - val_loss: 0.4853 - val_accuracy: 0.7804\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4823 - accuracy: 0.7776 - val_loss: 0.4938 - val_accuracy: 0.7633\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4802 - accuracy: 0.7813 - val_loss: 0.4904 - val_accuracy: 0.7761\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4712 - accuracy: 0.7904 - val_loss: 0.4922 - val_accuracy: 0.7676\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4750 - accuracy: 0.7819 - val_loss: 0.4802 - val_accuracy: 0.7783\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4731 - accuracy: 0.7872 - val_loss: 0.5262 - val_accuracy: 0.7484\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4768 - accuracy: 0.7829 - val_loss: 0.4832 - val_accuracy: 0.7825\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4710 - accuracy: 0.7819 - val_loss: 0.5001 - val_accuracy: 0.7889\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4744 - accuracy: 0.7835 - val_loss: 0.4810 - val_accuracy: 0.7761\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4704 - accuracy: 0.7856 - val_loss: 0.4790 - val_accuracy: 0.7825\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4721 - accuracy: 0.7824 - val_loss: 0.4773 - val_accuracy: 0.7761\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4714 - accuracy: 0.7861 - val_loss: 0.5112 - val_accuracy: 0.7783\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4709 - accuracy: 0.7883 - val_loss: 0.4893 - val_accuracy: 0.7740\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4703 - accuracy: 0.7851 - val_loss: 0.4859 - val_accuracy: 0.7676\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4675 - accuracy: 0.7824 - val_loss: 0.4800 - val_accuracy: 0.7910\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4648 - accuracy: 0.7835 - val_loss: 0.4972 - val_accuracy: 0.7719\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4683 - accuracy: 0.7861 - val_loss: 0.4772 - val_accuracy: 0.7740\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4677 - accuracy: 0.7925 - val_loss: 0.4941 - val_accuracy: 0.7697\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4674 - accuracy: 0.7867 - val_loss: 0.4950 - val_accuracy: 0.7740\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4651 - accuracy: 0.7867 - val_loss: 0.4819 - val_accuracy: 0.7783\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4686 - accuracy: 0.7925 - val_loss: 0.4929 - val_accuracy: 0.7719\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4648 - accuracy: 0.7867 - val_loss: 0.5135 - val_accuracy: 0.7804\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4675 - accuracy: 0.7899 - val_loss: 0.4846 - val_accuracy: 0.7761\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4634 - accuracy: 0.7824 - val_loss: 0.4902 - val_accuracy: 0.7719\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4680 - accuracy: 0.7856 - val_loss: 0.4847 - val_accuracy: 0.7783\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4705 - accuracy: 0.7861 - val_loss: 0.4837 - val_accuracy: 0.7804\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4632 - accuracy: 0.7883 - val_loss: 0.4888 - val_accuracy: 0.7761\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4659 - accuracy: 0.7888 - val_loss: 0.4864 - val_accuracy: 0.7719\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4605 - accuracy: 0.7915 - val_loss: 0.4800 - val_accuracy: 0.7740\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4605 - accuracy: 0.7899 - val_loss: 0.4881 - val_accuracy: 0.7783\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4659 - accuracy: 0.7883 - val_loss: 0.4881 - val_accuracy: 0.7740\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4649 - accuracy: 0.7899 - val_loss: 0.4907 - val_accuracy: 0.7676\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4645 - accuracy: 0.7893 - val_loss: 0.4967 - val_accuracy: 0.7761\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4622 - accuracy: 0.7909 - val_loss: 0.4815 - val_accuracy: 0.7740\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4646 - accuracy: 0.7957 - val_loss: 0.4834 - val_accuracy: 0.7719\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4605 - accuracy: 0.7941 - val_loss: 0.4896 - val_accuracy: 0.7697\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4616 - accuracy: 0.7909 - val_loss: 0.4850 - val_accuracy: 0.7719\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4608 - accuracy: 0.7867 - val_loss: 0.4881 - val_accuracy: 0.7740\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4617 - accuracy: 0.7931 - val_loss: 0.4867 - val_accuracy: 0.7676\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4581 - accuracy: 0.7877 - val_loss: 0.5028 - val_accuracy: 0.7804\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4615 - accuracy: 0.7851 - val_loss: 0.4993 - val_accuracy: 0.7569\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4572 - accuracy: 0.7915 - val_loss: 0.4831 - val_accuracy: 0.7804\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4553 - accuracy: 0.7904 - val_loss: 0.4987 - val_accuracy: 0.7761\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4576 - accuracy: 0.7973 - val_loss: 0.4858 - val_accuracy: 0.7783\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4618 - accuracy: 0.7915 - val_loss: 0.4917 - val_accuracy: 0.7804\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4593 - accuracy: 0.7888 - val_loss: 0.4906 - val_accuracy: 0.7783\n",
      "accuracy: 77.83%\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_175 (Dense)            (None, 500)               3500      \n",
      "_________________________________________________________________\n",
      "dense_176 (Dense)            (None, 100)               50100     \n",
      "_________________________________________________________________\n",
      "dense_177 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_178 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_179 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_180 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_181 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 94,101\n",
      "Trainable params: 94,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "368/375 [============================>.] - ETA: 0s - loss: 0.5554 - accuracy: 0.7234WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5549 - accuracy: 0.7237 - val_loss: 0.5019 - val_accuracy: 0.7505\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4944 - accuracy: 0.7723 - val_loss: 0.5033 - val_accuracy: 0.7719\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4922 - accuracy: 0.7749 - val_loss: 0.4832 - val_accuracy: 0.7740\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4840 - accuracy: 0.7803 - val_loss: 0.4971 - val_accuracy: 0.7676\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4846 - accuracy: 0.7771 - val_loss: 0.4991 - val_accuracy: 0.7697\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4776 - accuracy: 0.7776 - val_loss: 0.4940 - val_accuracy: 0.7804\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4784 - accuracy: 0.7835 - val_loss: 0.4870 - val_accuracy: 0.7761\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4819 - accuracy: 0.7840 - val_loss: 0.4844 - val_accuracy: 0.7783\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4777 - accuracy: 0.7771 - val_loss: 0.4933 - val_accuracy: 0.7740\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4737 - accuracy: 0.7824 - val_loss: 0.5027 - val_accuracy: 0.7761\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4774 - accuracy: 0.7792 - val_loss: 0.4876 - val_accuracy: 0.7761\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4681 - accuracy: 0.7840 - val_loss: 0.4793 - val_accuracy: 0.7761\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4818 - accuracy: 0.7707 - val_loss: 0.4888 - val_accuracy: 0.7612\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4674 - accuracy: 0.7819 - val_loss: 0.5031 - val_accuracy: 0.7676\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4792 - accuracy: 0.7803 - val_loss: 0.4861 - val_accuracy: 0.7633\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4703 - accuracy: 0.7867 - val_loss: 0.4913 - val_accuracy: 0.7740\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4657 - accuracy: 0.7829 - val_loss: 0.4871 - val_accuracy: 0.7783\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4709 - accuracy: 0.7867 - val_loss: 0.4948 - val_accuracy: 0.7740\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4723 - accuracy: 0.7824 - val_loss: 0.4797 - val_accuracy: 0.7783\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4728 - accuracy: 0.7781 - val_loss: 0.4874 - val_accuracy: 0.7761\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4736 - accuracy: 0.7824 - val_loss: 0.4797 - val_accuracy: 0.7761\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4698 - accuracy: 0.7861 - val_loss: 0.4893 - val_accuracy: 0.7676\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4729 - accuracy: 0.7819 - val_loss: 0.4939 - val_accuracy: 0.7612\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4756 - accuracy: 0.7819 - val_loss: 0.4902 - val_accuracy: 0.7740\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4673 - accuracy: 0.7883 - val_loss: 0.4877 - val_accuracy: 0.7719\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4682 - accuracy: 0.7813 - val_loss: 0.4841 - val_accuracy: 0.7740\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4675 - accuracy: 0.7851 - val_loss: 0.4899 - val_accuracy: 0.7676\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4612 - accuracy: 0.7941 - val_loss: 0.5214 - val_accuracy: 0.7612\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4663 - accuracy: 0.7888 - val_loss: 0.4846 - val_accuracy: 0.7761\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4642 - accuracy: 0.7867 - val_loss: 0.4911 - val_accuracy: 0.7740\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4634 - accuracy: 0.7899 - val_loss: 0.5084 - val_accuracy: 0.7697\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4588 - accuracy: 0.7957 - val_loss: 0.4961 - val_accuracy: 0.7655\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4604 - accuracy: 0.7893 - val_loss: 0.4920 - val_accuracy: 0.7740\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4593 - accuracy: 0.7856 - val_loss: 0.4816 - val_accuracy: 0.7761\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4610 - accuracy: 0.7979 - val_loss: 0.4834 - val_accuracy: 0.7783\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4581 - accuracy: 0.7899 - val_loss: 0.4895 - val_accuracy: 0.7740\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4585 - accuracy: 0.7936 - val_loss: 0.4835 - val_accuracy: 0.7761\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4656 - accuracy: 0.7856 - val_loss: 0.5002 - val_accuracy: 0.7697\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4628 - accuracy: 0.7888 - val_loss: 0.4857 - val_accuracy: 0.7783\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4590 - accuracy: 0.7856 - val_loss: 0.4865 - val_accuracy: 0.7612\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4613 - accuracy: 0.7941 - val_loss: 0.4843 - val_accuracy: 0.7804\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4596 - accuracy: 0.7872 - val_loss: 0.4807 - val_accuracy: 0.7761\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4601 - accuracy: 0.7925 - val_loss: 0.4847 - val_accuracy: 0.7697\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4571 - accuracy: 0.7856 - val_loss: 0.4796 - val_accuracy: 0.7804\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4580 - accuracy: 0.7952 - val_loss: 0.4856 - val_accuracy: 0.7697\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4595 - accuracy: 0.7845 - val_loss: 0.4907 - val_accuracy: 0.7655\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4552 - accuracy: 0.7979 - val_loss: 0.4869 - val_accuracy: 0.7761\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4563 - accuracy: 0.7931 - val_loss: 0.5050 - val_accuracy: 0.7612\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4583 - accuracy: 0.7899 - val_loss: 0.5016 - val_accuracy: 0.7676\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4561 - accuracy: 0.7893 - val_loss: 0.4880 - val_accuracy: 0.7783\n",
      "accuracy: 77.83%\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_182 (Dense)            (None, 500)               3500      \n",
      "_________________________________________________________________\n",
      "dense_183 (Dense)            (None, 100)               50100     \n",
      "_________________________________________________________________\n",
      "dense_184 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_185 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_186 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_187 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_188 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 94,101\n",
      "Trainable params: 94,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5563 - accuracy: 0.7264 - val_loss: 0.5156 - val_accuracy: 0.7591\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4985 - accuracy: 0.7744 - val_loss: 0.4945 - val_accuracy: 0.7676\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4880 - accuracy: 0.7691 - val_loss: 0.4947 - val_accuracy: 0.7612\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4861 - accuracy: 0.7824 - val_loss: 0.4857 - val_accuracy: 0.7804\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4796 - accuracy: 0.7840 - val_loss: 0.4914 - val_accuracy: 0.7846\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4781 - accuracy: 0.7829 - val_loss: 0.4900 - val_accuracy: 0.7740\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4759 - accuracy: 0.7899 - val_loss: 0.4929 - val_accuracy: 0.7719\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4770 - accuracy: 0.7781 - val_loss: 0.5026 - val_accuracy: 0.7719\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4745 - accuracy: 0.7845 - val_loss: 0.4963 - val_accuracy: 0.7783\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4759 - accuracy: 0.7861 - val_loss: 0.5141 - val_accuracy: 0.7697\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4753 - accuracy: 0.7819 - val_loss: 0.4832 - val_accuracy: 0.7719\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4713 - accuracy: 0.7872 - val_loss: 0.4914 - val_accuracy: 0.7719\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4775 - accuracy: 0.7787 - val_loss: 0.4836 - val_accuracy: 0.7783\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4757 - accuracy: 0.7808 - val_loss: 0.4841 - val_accuracy: 0.7804\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4729 - accuracy: 0.7808 - val_loss: 0.4917 - val_accuracy: 0.7719\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4684 - accuracy: 0.7797 - val_loss: 0.4832 - val_accuracy: 0.7804\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4670 - accuracy: 0.7851 - val_loss: 0.4894 - val_accuracy: 0.7697\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4673 - accuracy: 0.7845 - val_loss: 0.4801 - val_accuracy: 0.7846\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4727 - accuracy: 0.7819 - val_loss: 0.4889 - val_accuracy: 0.7697\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4742 - accuracy: 0.7792 - val_loss: 0.4838 - val_accuracy: 0.7740\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4728 - accuracy: 0.7813 - val_loss: 0.4843 - val_accuracy: 0.7889\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4646 - accuracy: 0.7845 - val_loss: 0.4824 - val_accuracy: 0.7783\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4658 - accuracy: 0.7893 - val_loss: 0.4850 - val_accuracy: 0.7719\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4672 - accuracy: 0.7840 - val_loss: 0.4805 - val_accuracy: 0.7804\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4648 - accuracy: 0.7845 - val_loss: 0.4806 - val_accuracy: 0.7719\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4630 - accuracy: 0.7883 - val_loss: 0.5039 - val_accuracy: 0.7740\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4631 - accuracy: 0.7851 - val_loss: 0.5081 - val_accuracy: 0.7612\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4648 - accuracy: 0.7925 - val_loss: 0.4970 - val_accuracy: 0.7633\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4682 - accuracy: 0.7872 - val_loss: 0.4829 - val_accuracy: 0.7889\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4653 - accuracy: 0.7851 - val_loss: 0.4815 - val_accuracy: 0.7761\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4617 - accuracy: 0.7909 - val_loss: 0.4834 - val_accuracy: 0.7761\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4635 - accuracy: 0.7867 - val_loss: 0.4873 - val_accuracy: 0.7740\n",
      "Epoch 33/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4562 - accuracy: 0.7909 - val_loss: 0.4798 - val_accuracy: 0.7804\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4628 - accuracy: 0.7883 - val_loss: 0.4947 - val_accuracy: 0.7655\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4618 - accuracy: 0.7899 - val_loss: 0.4932 - val_accuracy: 0.7825\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4638 - accuracy: 0.7904 - val_loss: 0.4836 - val_accuracy: 0.7804\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4613 - accuracy: 0.7915 - val_loss: 0.4816 - val_accuracy: 0.7846\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4638 - accuracy: 0.7877 - val_loss: 0.4860 - val_accuracy: 0.7719\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4569 - accuracy: 0.7920 - val_loss: 0.4861 - val_accuracy: 0.7740\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4626 - accuracy: 0.7819 - val_loss: 0.4900 - val_accuracy: 0.7697\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4635 - accuracy: 0.7883 - val_loss: 0.4852 - val_accuracy: 0.7783\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4578 - accuracy: 0.7957 - val_loss: 0.4870 - val_accuracy: 0.7740\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4597 - accuracy: 0.7941 - val_loss: 0.4778 - val_accuracy: 0.7846\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4625 - accuracy: 0.7867 - val_loss: 0.4788 - val_accuracy: 0.7846\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4575 - accuracy: 0.7915 - val_loss: 0.4921 - val_accuracy: 0.7740\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4566 - accuracy: 0.7872 - val_loss: 0.4877 - val_accuracy: 0.7740\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4574 - accuracy: 0.7893 - val_loss: 0.4978 - val_accuracy: 0.7612\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4567 - accuracy: 0.7899 - val_loss: 0.5027 - val_accuracy: 0.7783\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4549 - accuracy: 0.7936 - val_loss: 0.4812 - val_accuracy: 0.7804\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4537 - accuracy: 0.7952 - val_loss: 0.4909 - val_accuracy: 0.7676\n",
      "accuracy: 76.76%\n",
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_189 (Dense)            (None, 500)               3500      \n",
      "_________________________________________________________________\n",
      "dense_190 (Dense)            (None, 100)               50100     \n",
      "_________________________________________________________________\n",
      "dense_191 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_192 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_193 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_194 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_195 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 94,101\n",
      "Trainable params: 94,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5331 - accuracy: 0.7317 - val_loss: 0.5343 - val_accuracy: 0.7463\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4925 - accuracy: 0.7701 - val_loss: 0.5308 - val_accuracy: 0.7356\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4930 - accuracy: 0.7659 - val_loss: 0.4877 - val_accuracy: 0.7719\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4865 - accuracy: 0.7685 - val_loss: 0.4814 - val_accuracy: 0.7783\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4850 - accuracy: 0.7760 - val_loss: 0.4987 - val_accuracy: 0.7761\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4793 - accuracy: 0.7781 - val_loss: 0.4871 - val_accuracy: 0.7761\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4763 - accuracy: 0.7771 - val_loss: 0.5230 - val_accuracy: 0.7612\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4737 - accuracy: 0.7840 - val_loss: 0.5083 - val_accuracy: 0.7825\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4738 - accuracy: 0.7808 - val_loss: 0.4826 - val_accuracy: 0.7740\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4702 - accuracy: 0.7803 - val_loss: 0.4975 - val_accuracy: 0.7697\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4734 - accuracy: 0.7797 - val_loss: 0.5023 - val_accuracy: 0.7633\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4719 - accuracy: 0.7808 - val_loss: 0.4815 - val_accuracy: 0.7804\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4747 - accuracy: 0.7845 - val_loss: 0.4829 - val_accuracy: 0.7719\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4705 - accuracy: 0.7797 - val_loss: 0.4808 - val_accuracy: 0.7697\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4717 - accuracy: 0.7883 - val_loss: 0.4795 - val_accuracy: 0.7761\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4651 - accuracy: 0.7845 - val_loss: 0.4858 - val_accuracy: 0.7740\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4671 - accuracy: 0.7845 - val_loss: 0.4824 - val_accuracy: 0.7825\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4701 - accuracy: 0.7845 - val_loss: 0.5373 - val_accuracy: 0.7399\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4662 - accuracy: 0.7851 - val_loss: 0.4911 - val_accuracy: 0.7612\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4712 - accuracy: 0.7787 - val_loss: 0.4979 - val_accuracy: 0.7804\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4669 - accuracy: 0.7872 - val_loss: 0.5032 - val_accuracy: 0.7804\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4679 - accuracy: 0.7856 - val_loss: 0.4788 - val_accuracy: 0.7719\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4665 - accuracy: 0.7813 - val_loss: 0.4918 - val_accuracy: 0.7804\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4659 - accuracy: 0.7952 - val_loss: 0.4902 - val_accuracy: 0.7697\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4641 - accuracy: 0.7888 - val_loss: 0.4842 - val_accuracy: 0.7761\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4632 - accuracy: 0.7829 - val_loss: 0.5112 - val_accuracy: 0.7591\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4660 - accuracy: 0.7856 - val_loss: 0.4905 - val_accuracy: 0.7633\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4700 - accuracy: 0.7867 - val_loss: 0.4783 - val_accuracy: 0.7719\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4629 - accuracy: 0.7909 - val_loss: 0.4877 - val_accuracy: 0.7804\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4626 - accuracy: 0.7920 - val_loss: 0.4889 - val_accuracy: 0.7868\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4642 - accuracy: 0.7877 - val_loss: 0.4825 - val_accuracy: 0.7740\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4624 - accuracy: 0.7883 - val_loss: 0.5008 - val_accuracy: 0.7697\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4615 - accuracy: 0.7899 - val_loss: 0.4853 - val_accuracy: 0.7761\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4618 - accuracy: 0.7867 - val_loss: 0.4958 - val_accuracy: 0.7676\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4593 - accuracy: 0.7893 - val_loss: 0.4790 - val_accuracy: 0.7740\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4614 - accuracy: 0.7952 - val_loss: 0.5076 - val_accuracy: 0.7783\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4552 - accuracy: 0.7904 - val_loss: 0.4789 - val_accuracy: 0.7825\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4645 - accuracy: 0.7904 - val_loss: 0.4879 - val_accuracy: 0.7719\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4596 - accuracy: 0.7963 - val_loss: 0.4825 - val_accuracy: 0.7846\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4604 - accuracy: 0.7899 - val_loss: 0.4930 - val_accuracy: 0.7719\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4623 - accuracy: 0.7877 - val_loss: 0.5327 - val_accuracy: 0.7399\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4584 - accuracy: 0.7888 - val_loss: 0.4827 - val_accuracy: 0.7804\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4538 - accuracy: 0.7968 - val_loss: 0.5006 - val_accuracy: 0.7548\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4598 - accuracy: 0.7957 - val_loss: 0.4913 - val_accuracy: 0.7740\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4600 - accuracy: 0.7915 - val_loss: 0.4743 - val_accuracy: 0.7783\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4572 - accuracy: 0.7941 - val_loss: 0.4864 - val_accuracy: 0.7761\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4605 - accuracy: 0.7899 - val_loss: 0.4957 - val_accuracy: 0.7655\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4609 - accuracy: 0.7888 - val_loss: 0.4821 - val_accuracy: 0.7783\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4536 - accuracy: 0.7915 - val_loss: 0.4996 - val_accuracy: 0.7697\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4566 - accuracy: 0.7925 - val_loss: 0.4866 - val_accuracy: 0.7719\n",
      "accuracy: 77.19%\n",
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_196 (Dense)            (None, 500)               3500      \n",
      "_________________________________________________________________\n",
      "dense_197 (Dense)            (None, 100)               50100     \n",
      "_________________________________________________________________\n",
      "dense_198 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_199 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_200 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_201 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_202 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 94,101\n",
      "Trainable params: 94,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5534 - accuracy: 0.7301 - val_loss: 0.5612 - val_accuracy: 0.7505\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4964 - accuracy: 0.7669 - val_loss: 0.4917 - val_accuracy: 0.7569\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4979 - accuracy: 0.7717 - val_loss: 0.4911 - val_accuracy: 0.7655\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4913 - accuracy: 0.7749 - val_loss: 0.4823 - val_accuracy: 0.7804\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4818 - accuracy: 0.7712 - val_loss: 0.5062 - val_accuracy: 0.7740\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4817 - accuracy: 0.7765 - val_loss: 0.4947 - val_accuracy: 0.7697\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4795 - accuracy: 0.7787 - val_loss: 0.5029 - val_accuracy: 0.7697\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4786 - accuracy: 0.7691 - val_loss: 0.4856 - val_accuracy: 0.7740\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4836 - accuracy: 0.7680 - val_loss: 0.4848 - val_accuracy: 0.7804\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4806 - accuracy: 0.7824 - val_loss: 0.4849 - val_accuracy: 0.7761\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4682 - accuracy: 0.7861 - val_loss: 0.4859 - val_accuracy: 0.7804\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4708 - accuracy: 0.7824 - val_loss: 0.5190 - val_accuracy: 0.7612\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4735 - accuracy: 0.7819 - val_loss: 0.4917 - val_accuracy: 0.7569\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4734 - accuracy: 0.7803 - val_loss: 0.4895 - val_accuracy: 0.7761\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4705 - accuracy: 0.7845 - val_loss: 0.4938 - val_accuracy: 0.7676\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4751 - accuracy: 0.7829 - val_loss: 0.4832 - val_accuracy: 0.7761\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4695 - accuracy: 0.7824 - val_loss: 0.4931 - val_accuracy: 0.7527\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4725 - accuracy: 0.7893 - val_loss: 0.4826 - val_accuracy: 0.7804\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4693 - accuracy: 0.7781 - val_loss: 0.4849 - val_accuracy: 0.7804\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4689 - accuracy: 0.7797 - val_loss: 0.4815 - val_accuracy: 0.7633\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4689 - accuracy: 0.7755 - val_loss: 0.5017 - val_accuracy: 0.7783\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4693 - accuracy: 0.7840 - val_loss: 0.4832 - val_accuracy: 0.7825\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4657 - accuracy: 0.7867 - val_loss: 0.4904 - val_accuracy: 0.7783\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4665 - accuracy: 0.7899 - val_loss: 0.4823 - val_accuracy: 0.7719\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4654 - accuracy: 0.7856 - val_loss: 0.5120 - val_accuracy: 0.7761\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4694 - accuracy: 0.7819 - val_loss: 0.4817 - val_accuracy: 0.7804\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4686 - accuracy: 0.7856 - val_loss: 0.4836 - val_accuracy: 0.7740\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4670 - accuracy: 0.7877 - val_loss: 0.4856 - val_accuracy: 0.7783\n",
      "Epoch 29/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4706 - accuracy: 0.7781 - val_loss: 0.4772 - val_accuracy: 0.7783\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4616 - accuracy: 0.7920 - val_loss: 0.4922 - val_accuracy: 0.7740\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4633 - accuracy: 0.7861 - val_loss: 0.4848 - val_accuracy: 0.7697\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4657 - accuracy: 0.7893 - val_loss: 0.4945 - val_accuracy: 0.7676\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4676 - accuracy: 0.7867 - val_loss: 0.4983 - val_accuracy: 0.7761\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4617 - accuracy: 0.7925 - val_loss: 0.4847 - val_accuracy: 0.7846\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4646 - accuracy: 0.7888 - val_loss: 0.4821 - val_accuracy: 0.7804\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4625 - accuracy: 0.7931 - val_loss: 0.4808 - val_accuracy: 0.7825\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4596 - accuracy: 0.7909 - val_loss: 0.4919 - val_accuracy: 0.7761\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4608 - accuracy: 0.7893 - val_loss: 0.5123 - val_accuracy: 0.7612\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4585 - accuracy: 0.7963 - val_loss: 0.4995 - val_accuracy: 0.7804\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4645 - accuracy: 0.7813 - val_loss: 0.4948 - val_accuracy: 0.7783\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4616 - accuracy: 0.7931 - val_loss: 0.5005 - val_accuracy: 0.7783\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4615 - accuracy: 0.7883 - val_loss: 0.4937 - val_accuracy: 0.7804\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4595 - accuracy: 0.7931 - val_loss: 0.5171 - val_accuracy: 0.7548\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4622 - accuracy: 0.7819 - val_loss: 0.4835 - val_accuracy: 0.7740\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4566 - accuracy: 0.7925 - val_loss: 0.4892 - val_accuracy: 0.7804\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4593 - accuracy: 0.7893 - val_loss: 0.4865 - val_accuracy: 0.7719\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4580 - accuracy: 0.7947 - val_loss: 0.5010 - val_accuracy: 0.7676\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4619 - accuracy: 0.7893 - val_loss: 0.4876 - val_accuracy: 0.7697\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4561 - accuracy: 0.7877 - val_loss: 0.5073 - val_accuracy: 0.7612\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4566 - accuracy: 0.7888 - val_loss: 0.4889 - val_accuracy: 0.7740\n",
      "accuracy: 77.40%\n",
      "77.33% (+/- 0.56%)\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "seed = 7\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "cvscores = []\n",
    "for train, test in kfold.split(X, y_sample):\n",
    "  # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(500, input_dim=6, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    model.fit(x_train,y_train, epochs=50, batch_size=5, validation_data=(x_test, y_test))\n",
    "    # evaluate the mode\n",
    "    scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    cvscores.append(scores[1] * 100)\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (numpy.mean(cvscores), numpy.std(cvscores)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
