{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, SimpleRNN\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import seaborn as sb\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation, Dropout, Dense\n",
    "from keras.layers import Flatten, LSTM\n",
    "from keras.layers import GlobalMaxPooling1D\n",
    "from keras.models import Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import Input\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers import Bidirectional\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age (y)</th>\n",
       "      <th>Gender(1, male; 2, female)</th>\n",
       "      <th>BMI(kg/m2)</th>\n",
       "      <th>censor of diabetes at followup(1, Yes; 0, No)</th>\n",
       "      <th>smoking status(1,current smoker;2, ever smoker;3,never smoker)</th>\n",
       "      <th>drinking status(1,current drinker;2, ever drinker;3,never drinker)</th>\n",
       "      <th>family histroy of diabetes(1,Yes;0,No)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>19.3</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>23.1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>18.1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>211828</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>24.5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>211829</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>18.8</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>211830</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>17.1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>211831</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>211832</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>27.7</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>211833 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age (y)  Gender(1, male; 2, female)  BMI(kg/m2)  \\\n",
       "0            43                           2        19.3   \n",
       "1            34                           1        20.0   \n",
       "2            32                           2        20.7   \n",
       "3            59                           1        23.1   \n",
       "4            30                           2        18.1   \n",
       "...         ...                         ...         ...   \n",
       "211828       41                           1        24.5   \n",
       "211829       31                           2        18.8   \n",
       "211830       30                           2        17.1   \n",
       "211831       43                           1        25.6   \n",
       "211832       57                           1        27.7   \n",
       "\n",
       "        censor of diabetes at followup(1, Yes; 0, No)  \\\n",
       "0                                                   0   \n",
       "1                                                   0   \n",
       "2                                                   0   \n",
       "3                                                   0   \n",
       "4                                                   0   \n",
       "...                                               ...   \n",
       "211828                                              0   \n",
       "211829                                              0   \n",
       "211830                                              0   \n",
       "211831                                              0   \n",
       "211832                                              1   \n",
       "\n",
       "        smoking status(1,current smoker;2, ever smoker;3,never smoker)  \\\n",
       "0                                                     3.0                \n",
       "1                                                     NaN                \n",
       "2                                                     NaN                \n",
       "3                                                     3.0                \n",
       "4                                                     NaN                \n",
       "...                                                   ...                \n",
       "211828                                                NaN                \n",
       "211829                                                NaN                \n",
       "211830                                                NaN                \n",
       "211831                                                NaN                \n",
       "211832                                                1.0                \n",
       "\n",
       "        drinking status(1,current drinker;2, ever drinker;3,never drinker)  \\\n",
       "0                                                     3.0                    \n",
       "1                                                     NaN                    \n",
       "2                                                     NaN                    \n",
       "3                                                     3.0                    \n",
       "4                                                     NaN                    \n",
       "...                                                   ...                    \n",
       "211828                                                NaN                    \n",
       "211829                                                NaN                    \n",
       "211830                                                NaN                    \n",
       "211831                                                NaN                    \n",
       "211832                                                2.0                    \n",
       "\n",
       "        family histroy of diabetes(1,Yes;0,No)  \n",
       "0                                            1  \n",
       "1                                            0  \n",
       "2                                            0  \n",
       "3                                            0  \n",
       "4                                            0  \n",
       "...                                        ...  \n",
       "211828                                       0  \n",
       "211829                                       0  \n",
       "211830                                       0  \n",
       "211831                                       0  \n",
       "211832                                       0  \n",
       "\n",
       "[211833 rows x 7 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading data from csv file that is in same directory as python process\n",
    "col_list = [\"Age (y)\",\"Gender(1, male; 2, female)\",\"BMI(kg/m2)\",\"censor of diabetes at followup(1, Yes; 0, No)\",\"smoking status(1,current smoker;2, ever smoker;3,never smoker)\",\n",
    "            \"drinking status(1,current drinker;2, ever drinker;3,never drinker)\",\"family histroy of diabetes(1,Yes;0,No)\"]\n",
    "data1= pd.read_csv(\"RC Health Care Data-20180820.csv\",usecols=col_list)\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Outcome</th>\n",
       "      <th>smoking</th>\n",
       "      <th>drinking</th>\n",
       "      <th>family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>19.3</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>23.1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>18.1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>211828</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>24.5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>211829</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>18.8</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>211830</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>17.1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>211831</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>211832</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>27.7</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>211833 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age  Gender   BMI  Outcome  smoking  drinking  family\n",
       "0        43       2  19.3        0      3.0       3.0       1\n",
       "1        34       1  20.0        0      NaN       NaN       0\n",
       "2        32       2  20.7        0      NaN       NaN       0\n",
       "3        59       1  23.1        0      3.0       3.0       0\n",
       "4        30       2  18.1        0      NaN       NaN       0\n",
       "...     ...     ...   ...      ...      ...       ...     ...\n",
       "211828   41       1  24.5        0      NaN       NaN       0\n",
       "211829   31       2  18.8        0      NaN       NaN       0\n",
       "211830   30       2  17.1        0      NaN       NaN       0\n",
       "211831   43       1  25.6        0      NaN       NaN       0\n",
       "211832   57       1  27.7        1      1.0       2.0       0\n",
       "\n",
       "[211833 rows x 7 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# changing columns using .columns() \n",
    "data1.columns = ['Age', 'Gender', 'BMI', 'Outcome', \n",
    "                'smoking', 'drinking', 'family']\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Outcome</th>\n",
       "      <th>smoking</th>\n",
       "      <th>drinking</th>\n",
       "      <th>family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>211833.000000</td>\n",
       "      <td>211833.000000</td>\n",
       "      <td>211833.000000</td>\n",
       "      <td>211833.000000</td>\n",
       "      <td>60230.000000</td>\n",
       "      <td>60230.000000</td>\n",
       "      <td>211833.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>42.097567</td>\n",
       "      <td>1.451818</td>\n",
       "      <td>23.235742</td>\n",
       "      <td>0.019704</td>\n",
       "      <td>2.556550</td>\n",
       "      <td>2.806442</td>\n",
       "      <td>0.020507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>12.649956</td>\n",
       "      <td>0.497674</td>\n",
       "      <td>3.342934</td>\n",
       "      <td>0.138982</td>\n",
       "      <td>0.804845</td>\n",
       "      <td>0.448283</td>\n",
       "      <td>0.141726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>25.380000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>52.700000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Age         Gender            BMI        Outcome  \\\n",
       "count  211833.000000  211833.000000  211833.000000  211833.000000   \n",
       "mean       42.097567       1.451818      23.235742       0.019704   \n",
       "std        12.649956       0.497674       3.342934       0.138982   \n",
       "min        20.000000       1.000000      15.000000       0.000000   \n",
       "25%        32.000000       1.000000      20.800000       0.000000   \n",
       "50%        39.000000       1.000000      23.000000       0.000000   \n",
       "75%        50.000000       2.000000      25.380000       0.000000   \n",
       "max        99.000000       2.000000      52.700000       1.000000   \n",
       "\n",
       "            smoking      drinking         family  \n",
       "count  60230.000000  60230.000000  211833.000000  \n",
       "mean       2.556550      2.806442       0.020507  \n",
       "std        0.804845      0.448283       0.141726  \n",
       "min        1.000000      1.000000       0.000000  \n",
       "25%        3.000000      3.000000       0.000000  \n",
       "50%        3.000000      3.000000       0.000000  \n",
       "75%        3.000000      3.000000       0.000000  \n",
       "max        3.000000      3.000000       1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: MatplotlibDeprecationWarning: \n",
      "The 'normed' kwarg was deprecated in Matplotlib 2.1 and will be removed in 3.1. Use 'density' instead.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_bins = 10\n",
    "plt.hist(data1['Age'], num_bins, normed=1, facecolor='blue', alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age              0\n",
       "Gender           0\n",
       "BMI              0\n",
       "Outcome          0\n",
       "smoking     151603\n",
       "drinking    151603\n",
       "family           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Outcome</th>\n",
       "      <th>smoking</th>\n",
       "      <th>drinking</th>\n",
       "      <th>family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>19.3</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>23.1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>22.4</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>20.3</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>24.9</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>211799</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>24.3</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>211806</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>211812</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>211826</td>\n",
       "      <td>68</td>\n",
       "      <td>2</td>\n",
       "      <td>28.4</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>211832</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>27.7</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60230 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age  Gender   BMI  Outcome  smoking  drinking  family\n",
       "0        43       2  19.3        0      3.0       3.0       1\n",
       "3        59       1  23.1        0      3.0       3.0       0\n",
       "9        31       1  22.4        0      3.0       3.0       0\n",
       "16       25       2  20.3        0      3.0       3.0       0\n",
       "19       66       1  24.9        0      1.0       3.0       0\n",
       "...     ...     ...   ...      ...      ...       ...     ...\n",
       "211799   38       1  24.3        0      2.0       3.0       0\n",
       "211806   57       1  25.1        0      1.0       3.0       0\n",
       "211812   31       2  22.9        0      3.0       3.0       0\n",
       "211826   68       2  28.4        0      3.0       3.0       0\n",
       "211832   57       1  27.7        1      1.0       2.0       0\n",
       "\n",
       "[60230 rows x 7 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1=data1.dropna()\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 60230 entries, 0 to 211832\n",
      "Data columns (total 7 columns):\n",
      "Age         60230 non-null int64\n",
      "Gender      60230 non-null int64\n",
      "BMI         60230 non-null float64\n",
      "Outcome     60230 non-null int64\n",
      "smoking     60230 non-null float64\n",
      "drinking    60230 non-null float64\n",
      "family      60230 non-null int64\n",
      "dtypes: float64(3), int64(4)\n",
      "memory usage: 3.7 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(data1.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outcome\n",
      "0    59058\n",
      "1     1172\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data1\n",
    "#groupby and size is used to return the class count of the target variable\n",
    "class_count=data1.groupby('Outcome').size()\n",
    "print(class_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_class_0, count_class_1 = data1.Outcome.value_counts()\n",
    "df_class_0 = data1[data1['Outcome'] == 0]\n",
    "df_class_1 = data1[data1['Outcome'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random under-sampling:\n",
      "1    1172\n",
      "0    1172\n",
      "Name: Outcome, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x16f3776e108>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#performing random under sampling to overcome the biased nature of the model\n",
    "df_class_0_under = df_class_0.sample(count_class_1)\n",
    "df_test_under = pd.concat([df_class_0_under, df_class_1], axis=0)\n",
    "print('Random under-sampling:')\n",
    "print(df_test_under.Outcome.value_counts())\n",
    "#plot that gives the count of each class\n",
    "df_test_under.Outcome.value_counts().plot(kind='bar', title='Count (target)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "143730    0\n",
       "79410     0\n",
       "3864      0\n",
       "96808     0\n",
       "145098    0\n",
       "         ..\n",
       "211159    1\n",
       "211313    1\n",
       "211395    1\n",
       "211655    1\n",
       "211832    1\n",
       "Name: Outcome, Length: 2344, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#target variable after sampling\n",
    "y_sample= df_test_under.Outcome\n",
    "#features after sampling\n",
    "X_sample=df_test_under.drop('Outcome', axis=1)\n",
    "y_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>BMI</th>\n",
       "      <th>smoking</th>\n",
       "      <th>drinking</th>\n",
       "      <th>family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>143730</td>\n",
       "      <td>78</td>\n",
       "      <td>2</td>\n",
       "      <td>20.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79410</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>20.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3864</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>22.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96808</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145098</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>26.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>211159</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>20.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>211313</td>\n",
       "      <td>71</td>\n",
       "      <td>2</td>\n",
       "      <td>27.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>211395</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>24.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>211655</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>23.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>211832</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>27.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2344 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age  Gender   BMI  smoking  drinking  family\n",
       "143730   78       2  20.7      3.0       3.0       0\n",
       "79410    44       1  20.5      1.0       3.0       0\n",
       "3864     38       1  22.9      3.0       3.0       0\n",
       "96808    40       2  19.0      3.0       3.0       0\n",
       "145098   31       1  26.9      3.0       3.0       0\n",
       "...     ...     ...   ...      ...       ...     ...\n",
       "211159   69       1  20.8      3.0       3.0       0\n",
       "211313   71       2  27.7      3.0       3.0       0\n",
       "211395   69       1  24.9      3.0       3.0       0\n",
       "211655   50       1  23.6      3.0       3.0       0\n",
       "211832   57       1  27.7      1.0       2.0       0\n",
       "\n",
       "[2344 rows x 6 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[78.   2.  20.7  3.   3.   0. ]\n",
      " [44.   1.  20.5  3.   1.   0. ]\n",
      " [38.   1.  22.9  3.   3.   0. ]\n",
      " ...\n",
      " [69.   1.  24.9  3.   3.   0. ]\n",
      " [50.   1.  23.6  3.   3.   0. ]\n",
      " [57.   1.  27.7  2.   1.   0. ]]\n"
     ]
    }
   ],
   "source": [
    "X = np.column_stack((X_sample['Age'],X_sample['Gender'],X_sample['BMI'],X_sample['drinking'],\n",
    "                    X_sample['smoking'],X_sample['family'])\n",
    "                   )\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.80882353, 1.        , 0.16600791, 1.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.30882353, 0.        , 0.15810277, 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.22058824, 0.        , 0.25296443, 1.        , 1.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.67647059, 0.        , 0.33201581, 1.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.39705882, 0.        , 0.28063241, 1.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.5       , 0.        , 0.44268775, 0.5       , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "min_max_scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_trainingset = min_max_scaler.fit_transform(X)\n",
    "scaled_trainingset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.80882353, 1.        , 0.16600791, 1.        , 1.        ,\n",
       "         0.        ]],\n",
       "\n",
       "       [[0.30882353, 0.        , 0.15810277, 1.        , 0.        ,\n",
       "         0.        ]],\n",
       "\n",
       "       [[0.22058824, 0.        , 0.25296443, 1.        , 1.        ,\n",
       "         0.        ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.67647059, 0.        , 0.33201581, 1.        , 1.        ,\n",
       "         0.        ]],\n",
       "\n",
       "       [[0.39705882, 0.        , 0.28063241, 1.        , 1.        ,\n",
       "         0.        ]],\n",
       "\n",
       "       [[0.5       , 0.        , 0.44268775, 0.5       , 0.        ,\n",
       "         0.        ]]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = array(scaled_trainingset).reshape(2344, 1, 6)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1875, 1, 6)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y_sample, test_size=0.20, random_state=42)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_56 (LSTM)               (None, 1, 50)             11400     \n",
      "_________________________________________________________________\n",
      "lstm_57 (LSTM)               (None, 27)                8424      \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 1)                 28        \n",
      "=================================================================\n",
      "Total params: 19,852\n",
      "Trainable params: 19,852\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(1, 6),return_sequences=True))\n",
    "model.add(LSTM(27, activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/49\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.6573 - accuracy: 0.6203 - val_loss: 0.5528 - val_accuracy: 0.7463\n",
      "Epoch 2/49\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5338 - accuracy: 0.7483 - val_loss: 0.5061 - val_accuracy: 0.7569\n",
      "Epoch 3/49\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5176 - accuracy: 0.7461 - val_loss: 0.5029 - val_accuracy: 0.7633\n",
      "Epoch 4/49\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.5092 - accuracy: 0.7568 - val_loss: 0.5456 - val_accuracy: 0.7228\n",
      "Epoch 5/49\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5091 - accuracy: 0.7653 - val_loss: 0.4888 - val_accuracy: 0.7889\n",
      "Epoch 6/49\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5104 - accuracy: 0.7595 - val_loss: 0.4963 - val_accuracy: 0.7783\n",
      "Epoch 7/49\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5067 - accuracy: 0.7552 - val_loss: 0.4831 - val_accuracy: 0.7910\n",
      "Epoch 8/49\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5022 - accuracy: 0.7643 - val_loss: 0.4801 - val_accuracy: 0.7953\n",
      "Epoch 9/49\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5010 - accuracy: 0.7632 - val_loss: 0.4988 - val_accuracy: 0.7697\n",
      "Epoch 10/49\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5037 - accuracy: 0.7600 - val_loss: 0.4781 - val_accuracy: 0.8017\n",
      "Epoch 11/49\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5041 - accuracy: 0.7627 - val_loss: 0.5105 - val_accuracy: 0.7484\n",
      "Epoch 12/49\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4991 - accuracy: 0.7637 - val_loss: 0.4762 - val_accuracy: 0.8060\n",
      "Epoch 13/49\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4993 - accuracy: 0.7600 - val_loss: 0.4879 - val_accuracy: 0.7783\n",
      "Epoch 14/49\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4971 - accuracy: 0.7627 - val_loss: 0.4932 - val_accuracy: 0.7655\n",
      "Epoch 15/49\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4972 - accuracy: 0.7605 - val_loss: 0.4731 - val_accuracy: 0.8038\n",
      "Epoch 16/49\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4982 - accuracy: 0.7616 - val_loss: 0.4733 - val_accuracy: 0.7996\n",
      "Epoch 17/49\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4944 - accuracy: 0.7573 - val_loss: 0.4823 - val_accuracy: 0.7889\n",
      "Epoch 18/49\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4931 - accuracy: 0.7653 - val_loss: 0.5015 - val_accuracy: 0.7655\n",
      "Epoch 19/49\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4951 - accuracy: 0.7632 - val_loss: 0.4759 - val_accuracy: 0.7910\n",
      "Epoch 20/49\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4918 - accuracy: 0.7627 - val_loss: 0.4739 - val_accuracy: 0.7996\n",
      "Epoch 21/49\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4903 - accuracy: 0.7563 - val_loss: 0.4746 - val_accuracy: 0.7974\n",
      "Epoch 22/49\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4918 - accuracy: 0.7595 - val_loss: 0.4717 - val_accuracy: 0.7910\n",
      "Epoch 23/49\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4901 - accuracy: 0.7616 - val_loss: 0.5025 - val_accuracy: 0.7548\n",
      "Epoch 24/49\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4910 - accuracy: 0.7621 - val_loss: 0.4697 - val_accuracy: 0.7996\n",
      "Epoch 25/49\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4889 - accuracy: 0.7589 - val_loss: 0.4785 - val_accuracy: 0.7868\n",
      "Epoch 26/49\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4894 - accuracy: 0.7669 - val_loss: 0.4739 - val_accuracy: 0.7910\n",
      "Epoch 27/49\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4865 - accuracy: 0.7664 - val_loss: 0.4705 - val_accuracy: 0.7953\n",
      "Epoch 28/49\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4893 - accuracy: 0.7611 - val_loss: 0.4706 - val_accuracy: 0.8017\n",
      "Epoch 29/49\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4879 - accuracy: 0.7680 - val_loss: 0.4678 - val_accuracy: 0.8017\n",
      "Epoch 30/49\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4876 - accuracy: 0.7621 - val_loss: 0.4778 - val_accuracy: 0.7889\n",
      "Epoch 31/49\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4867 - accuracy: 0.7733 - val_loss: 0.4757 - val_accuracy: 0.7910\n",
      "Epoch 32/49\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4863 - accuracy: 0.7669 - val_loss: 0.4779 - val_accuracy: 0.7889\n",
      "Epoch 33/49\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4859 - accuracy: 0.7648 - val_loss: 0.4721 - val_accuracy: 0.7953\n",
      "Epoch 34/49\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4866 - accuracy: 0.7621 - val_loss: 0.4730 - val_accuracy: 0.7953\n",
      "Epoch 35/49\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4854 - accuracy: 0.7648 - val_loss: 0.4667 - val_accuracy: 0.7996\n",
      "Epoch 36/49\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4852 - accuracy: 0.7680 - val_loss: 0.4716 - val_accuracy: 0.7953\n",
      "Epoch 37/49\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4859 - accuracy: 0.7707 - val_loss: 0.4676 - val_accuracy: 0.7996\n",
      "Epoch 38/49\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4858 - accuracy: 0.7717 - val_loss: 0.4734 - val_accuracy: 0.7889\n",
      "Epoch 39/49\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4833 - accuracy: 0.7728 - val_loss: 0.4740 - val_accuracy: 0.7953\n",
      "Epoch 40/49\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4869 - accuracy: 0.7659 - val_loss: 0.4668 - val_accuracy: 0.7996\n",
      "Epoch 41/49\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4838 - accuracy: 0.7621 - val_loss: 0.4709 - val_accuracy: 0.7910\n",
      "Epoch 42/49\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4838 - accuracy: 0.7669 - val_loss: 0.4898 - val_accuracy: 0.7740\n",
      "Epoch 43/49\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4852 - accuracy: 0.7707 - val_loss: 0.4700 - val_accuracy: 0.7974\n",
      "Epoch 44/49\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4864 - accuracy: 0.7675 - val_loss: 0.4776 - val_accuracy: 0.7889\n",
      "Epoch 45/49\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4827 - accuracy: 0.7707 - val_loss: 0.4691 - val_accuracy: 0.8038\n",
      "Epoch 46/49\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4836 - accuracy: 0.7675 - val_loss: 0.4890 - val_accuracy: 0.7761\n",
      "Epoch 47/49\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4837 - accuracy: 0.7717 - val_loss: 0.5226 - val_accuracy: 0.7591\n",
      "Epoch 48/49\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4859 - accuracy: 0.7723 - val_loss: 0.4677 - val_accuracy: 0.7974\n",
      "Epoch 49/49\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4835 - accuracy: 0.7691 - val_loss: 0.4683 - val_accuracy: 0.7996\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x16f4bee9948>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train, epochs=49, batch_size=5, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_class_nn_1 = model.predict_classes(x_test)\n",
    "y_pred_class_nn_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.800\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score# Print model performance and plot the roc curve\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['labelencoder1_X.joblib1.dat']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "from joblib import load\n",
    "from joblib import dump\n",
    "\n",
    "dump(min_max_scaler, \"labelencoder1_X.joblib1.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model.save(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5       , 0.        , 0.44268775, 0.5       , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(X[2343],\"test_case1.joblib1.dat\")\n",
    "X[2343]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.77      0.79       234\n",
      "           1       0.78      0.83      0.81       235\n",
      "\n",
      "    accuracy                           0.80       469\n",
      "   macro avg       0.80      0.80      0.80       469\n",
      "weighted avg       0.80      0.80      0.80       469\n",
      "\n",
      "[[180  54]\n",
      " [ 40 195]]\n"
     ]
    }
   ],
   "source": [
    "#classification report for precision, recall and f1-score for both class\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test,y_pred_class_nn_1, labels=[0,1]))\n",
    "confusion = metrics.confusion_matrix(y_test, y_pred_class_nn_1)\n",
    "print(confusion)\n",
    "#[row, column]\n",
    "TP = confusion[1, 1]\n",
    "TN = confusion[0, 0]\n",
    "FP = confusion[0, 1]\n",
    "FN = confusion[1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7995735607675906\n",
      "0.7995735607675906\n"
     ]
    }
   ],
   "source": [
    "# use float to perform true division, not integer division\n",
    "print((TP + TN) / float(TP + TN + FP + FN))\n",
    "print(metrics.accuracy_score(y_test, y_pred_class_nn_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20042643923240938\n",
      "0.20042643923240944\n"
     ]
    }
   ],
   "source": [
    "\n",
    "classification_error = (FP + FN) / float(TP + TN + FP + FN)\n",
    "\n",
    "print(classification_error)\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred_class_nn_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8297872340425532\n",
      "0.8297872340425532\n"
     ]
    }
   ],
   "source": [
    "sensitivity = TP / float(FN + TP)\n",
    "\n",
    "print(sensitivity)\n",
    "print(metrics.recall_score(y_test, y_pred_class_nn_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7692307692307693\n"
     ]
    }
   ],
   "source": [
    "specificity = TN / (TN + FP)\n",
    "\n",
    "print(specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23076923076923078\n",
      "0.23076923076923073\n"
     ]
    }
   ],
   "source": [
    "false_positive_rate = FP / float(TN + FP)\n",
    "\n",
    "print(false_positive_rate)\n",
    "print(1 - specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8297872340425532\n"
     ]
    }
   ],
   "source": [
    "recall = TP / float(TP + FN)\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7831325301204819\n",
      "0.7831325301204819\n"
     ]
    }
   ],
   "source": [
    "precision = TP / float(TP + FP)\n",
    "\n",
    "print(precision)\n",
    "print(metrics.precision_score(y_test, y_pred_class_nn_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.805785123966942\n"
     ]
    }
   ],
   "source": [
    "f1score= 2*(recall * precision) / (recall + precision)\n",
    "print(f1score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.41176471, 0.        , 0.36363636, 1.        , 1.        ,\n",
       "         0.        ]]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_try = np.array([x_train[134]])\n",
    "feature_try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model.predict_classes(feature_try)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_80 (LSTM)               (None, 1, 50)             11400     \n",
      "_________________________________________________________________\n",
      "lstm_81 (LSTM)               (None, 27)                8424      \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 1)                 28        \n",
      "=================================================================\n",
      "Total params: 19,852\n",
      "Trainable params: 19,852\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/48\n",
      "375/375 [==============================] - 7s 17ms/step - loss: 0.6282 - accuracy: 0.6800 - val_loss: 0.5254 - val_accuracy: 0.7207\n",
      "Epoch 2/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5212 - accuracy: 0.7408 - val_loss: 0.4969 - val_accuracy: 0.7719\n",
      "Epoch 3/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5133 - accuracy: 0.7531 - val_loss: 0.5072 - val_accuracy: 0.7633\n",
      "Epoch 4/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5138 - accuracy: 0.7493 - val_loss: 0.4887 - val_accuracy: 0.7868\n",
      "Epoch 5/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5125 - accuracy: 0.7536 - val_loss: 0.4929 - val_accuracy: 0.7868\n",
      "Epoch 6/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5108 - accuracy: 0.7600 - val_loss: 0.4887 - val_accuracy: 0.7868\n",
      "Epoch 7/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5062 - accuracy: 0.7616 - val_loss: 0.4830 - val_accuracy: 0.7889\n",
      "Epoch 8/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5064 - accuracy: 0.7632 - val_loss: 0.4856 - val_accuracy: 0.7996\n",
      "Epoch 9/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5038 - accuracy: 0.7696 - val_loss: 0.4816 - val_accuracy: 0.7932\n",
      "Epoch 10/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5046 - accuracy: 0.7621 - val_loss: 0.4903 - val_accuracy: 0.7846\n",
      "Epoch 11/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5049 - accuracy: 0.7627 - val_loss: 0.5045 - val_accuracy: 0.7569\n",
      "Epoch 12/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5025 - accuracy: 0.7664 - val_loss: 0.4791 - val_accuracy: 0.7974\n",
      "Epoch 13/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5017 - accuracy: 0.7584 - val_loss: 0.4775 - val_accuracy: 0.7910\n",
      "Epoch 14/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5035 - accuracy: 0.7648 - val_loss: 0.4806 - val_accuracy: 0.7910\n",
      "Epoch 15/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4998 - accuracy: 0.7664 - val_loss: 0.4852 - val_accuracy: 0.7761\n",
      "Epoch 16/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4996 - accuracy: 0.7627 - val_loss: 0.4760 - val_accuracy: 0.8017\n",
      "Epoch 17/48\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4971 - accuracy: 0.7648 - val_loss: 0.4944 - val_accuracy: 0.7676\n",
      "Epoch 18/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4999 - accuracy: 0.7621 - val_loss: 0.4742 - val_accuracy: 0.7996\n",
      "Epoch 19/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4961 - accuracy: 0.7696 - val_loss: 0.5002 - val_accuracy: 0.7612\n",
      "Epoch 20/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4945 - accuracy: 0.7621 - val_loss: 0.4741 - val_accuracy: 0.7910\n",
      "Epoch 21/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4933 - accuracy: 0.7680 - val_loss: 0.4938 - val_accuracy: 0.7655\n",
      "Epoch 22/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4957 - accuracy: 0.7648 - val_loss: 0.4795 - val_accuracy: 0.7868\n",
      "Epoch 23/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4917 - accuracy: 0.7712 - val_loss: 0.4775 - val_accuracy: 0.8017\n",
      "Epoch 24/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4925 - accuracy: 0.7659 - val_loss: 0.4717 - val_accuracy: 0.7910\n",
      "Epoch 25/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4898 - accuracy: 0.7675 - val_loss: 0.4686 - val_accuracy: 0.8038\n",
      "Epoch 26/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4928 - accuracy: 0.7643 - val_loss: 0.4688 - val_accuracy: 0.7910\n",
      "Epoch 27/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4888 - accuracy: 0.7627 - val_loss: 0.4781 - val_accuracy: 0.7889\n",
      "Epoch 28/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4874 - accuracy: 0.7643 - val_loss: 0.4823 - val_accuracy: 0.7825\n",
      "Epoch 29/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4861 - accuracy: 0.7712 - val_loss: 0.4681 - val_accuracy: 0.7996\n",
      "Epoch 30/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4880 - accuracy: 0.7733 - val_loss: 0.4669 - val_accuracy: 0.7974\n",
      "Epoch 31/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4876 - accuracy: 0.7707 - val_loss: 0.4708 - val_accuracy: 0.7932\n",
      "Epoch 32/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4849 - accuracy: 0.7653 - val_loss: 0.4684 - val_accuracy: 0.7932\n",
      "Epoch 33/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4845 - accuracy: 0.7739 - val_loss: 0.4637 - val_accuracy: 0.7996\n",
      "Epoch 34/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4877 - accuracy: 0.7707 - val_loss: 0.4650 - val_accuracy: 0.8038\n",
      "Epoch 35/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4847 - accuracy: 0.7659 - val_loss: 0.4636 - val_accuracy: 0.7932\n",
      "Epoch 36/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4862 - accuracy: 0.7712 - val_loss: 0.4652 - val_accuracy: 0.7996\n",
      "Epoch 37/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4850 - accuracy: 0.7717 - val_loss: 0.4727 - val_accuracy: 0.7953\n",
      "Epoch 38/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4837 - accuracy: 0.7707 - val_loss: 0.4688 - val_accuracy: 0.7932\n",
      "Epoch 39/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4843 - accuracy: 0.7691 - val_loss: 0.4642 - val_accuracy: 0.8017\n",
      "Epoch 40/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4841 - accuracy: 0.7712 - val_loss: 0.4759 - val_accuracy: 0.7825\n",
      "Epoch 41/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4828 - accuracy: 0.7685 - val_loss: 0.4661 - val_accuracy: 0.7932\n",
      "Epoch 42/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4845 - accuracy: 0.7691 - val_loss: 0.4699 - val_accuracy: 0.7889\n",
      "Epoch 43/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4839 - accuracy: 0.7712 - val_loss: 0.4659 - val_accuracy: 0.8038\n",
      "Epoch 44/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4842 - accuracy: 0.7723 - val_loss: 0.4701 - val_accuracy: 0.7953\n",
      "Epoch 45/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4831 - accuracy: 0.7691 - val_loss: 0.4718 - val_accuracy: 0.7953\n",
      "Epoch 46/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4838 - accuracy: 0.7712 - val_loss: 0.4753 - val_accuracy: 0.7846\n",
      "Epoch 47/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4843 - accuracy: 0.7685 - val_loss: 0.4639 - val_accuracy: 0.7974\n",
      "Epoch 48/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4831 - accuracy: 0.7717 - val_loss: 0.4829 - val_accuracy: 0.7825\n",
      "accuracy: 78.25%\n",
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_82 (LSTM)               (None, 1, 50)             11400     \n",
      "_________________________________________________________________\n",
      "lstm_83 (LSTM)               (None, 27)                8424      \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 1)                 28        \n",
      "=================================================================\n",
      "Total params: 19,852\n",
      "Trainable params: 19,852\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/48\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.6536 - accuracy: 0.6432 - val_loss: 0.5555 - val_accuracy: 0.7313\n",
      "Epoch 2/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5288 - accuracy: 0.7493 - val_loss: 0.4978 - val_accuracy: 0.7761\n",
      "Epoch 3/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5149 - accuracy: 0.7595 - val_loss: 0.4876 - val_accuracy: 0.7910\n",
      "Epoch 4/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5085 - accuracy: 0.7621 - val_loss: 0.4971 - val_accuracy: 0.7740\n",
      "Epoch 5/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5052 - accuracy: 0.7627 - val_loss: 0.4863 - val_accuracy: 0.7804\n",
      "Epoch 6/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5033 - accuracy: 0.7573 - val_loss: 0.4877 - val_accuracy: 0.7825\n",
      "Epoch 7/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5014 - accuracy: 0.7627 - val_loss: 0.4747 - val_accuracy: 0.7996\n",
      "Epoch 8/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4986 - accuracy: 0.7637 - val_loss: 0.4764 - val_accuracy: 0.7910\n",
      "Epoch 9/48\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5007 - accuracy: 0.7648 - val_loss: 0.4687 - val_accuracy: 0.7974\n",
      "Epoch 10/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4998 - accuracy: 0.7637 - val_loss: 0.4721 - val_accuracy: 0.7974\n",
      "Epoch 11/48\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4955 - accuracy: 0.7669 - val_loss: 0.4678 - val_accuracy: 0.7996\n",
      "Epoch 12/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4961 - accuracy: 0.7685 - val_loss: 0.4860 - val_accuracy: 0.7761\n",
      "Epoch 13/48\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4935 - accuracy: 0.7669 - val_loss: 0.4835 - val_accuracy: 0.7783\n",
      "Epoch 14/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4914 - accuracy: 0.7664 - val_loss: 0.4658 - val_accuracy: 0.8017\n",
      "Epoch 15/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4908 - accuracy: 0.7733 - val_loss: 0.4732 - val_accuracy: 0.7932\n",
      "Epoch 16/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4911 - accuracy: 0.7595 - val_loss: 0.4631 - val_accuracy: 0.7953\n",
      "Epoch 17/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4909 - accuracy: 0.7627 - val_loss: 0.4639 - val_accuracy: 0.7953\n",
      "Epoch 18/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4889 - accuracy: 0.7744 - val_loss: 0.4673 - val_accuracy: 0.7953\n",
      "Epoch 19/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4895 - accuracy: 0.7691 - val_loss: 0.4619 - val_accuracy: 0.7932\n",
      "Epoch 20/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4886 - accuracy: 0.7749 - val_loss: 0.4691 - val_accuracy: 0.7910\n",
      "Epoch 21/48\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4909 - accuracy: 0.7701 - val_loss: 0.4654 - val_accuracy: 0.7974\n",
      "Epoch 22/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4883 - accuracy: 0.7696 - val_loss: 0.4621 - val_accuracy: 0.7932\n",
      "Epoch 23/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4915 - accuracy: 0.7648 - val_loss: 0.4733 - val_accuracy: 0.7932\n",
      "Epoch 24/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4860 - accuracy: 0.7723 - val_loss: 0.4627 - val_accuracy: 0.7974\n",
      "Epoch 25/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4868 - accuracy: 0.7744 - val_loss: 0.4644 - val_accuracy: 0.8017\n",
      "Epoch 26/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4855 - accuracy: 0.7680 - val_loss: 0.4670 - val_accuracy: 0.7996\n",
      "Epoch 27/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4854 - accuracy: 0.7680 - val_loss: 0.4697 - val_accuracy: 0.7996\n",
      "Epoch 28/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4858 - accuracy: 0.7728 - val_loss: 0.4696 - val_accuracy: 0.7910\n",
      "Epoch 29/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4845 - accuracy: 0.7749 - val_loss: 0.4689 - val_accuracy: 0.7953\n",
      "Epoch 30/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4842 - accuracy: 0.7707 - val_loss: 0.4762 - val_accuracy: 0.7846\n",
      "Epoch 31/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4845 - accuracy: 0.7696 - val_loss: 0.4703 - val_accuracy: 0.7910\n",
      "Epoch 32/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4861 - accuracy: 0.7643 - val_loss: 0.4645 - val_accuracy: 0.7996\n",
      "Epoch 33/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4837 - accuracy: 0.7680 - val_loss: 0.4664 - val_accuracy: 0.7974\n",
      "Epoch 34/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4838 - accuracy: 0.7701 - val_loss: 0.4681 - val_accuracy: 0.7953\n",
      "Epoch 35/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4834 - accuracy: 0.7707 - val_loss: 0.4645 - val_accuracy: 0.7996\n",
      "Epoch 36/48\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4838 - accuracy: 0.7691 - val_loss: 0.4679 - val_accuracy: 0.7996\n",
      "Epoch 37/48\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4834 - accuracy: 0.7744 - val_loss: 0.4925 - val_accuracy: 0.7825\n",
      "Epoch 38/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4849 - accuracy: 0.7680 - val_loss: 0.4854 - val_accuracy: 0.7804\n",
      "Epoch 39/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4815 - accuracy: 0.7723 - val_loss: 0.4649 - val_accuracy: 0.7996\n",
      "Epoch 40/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4832 - accuracy: 0.7659 - val_loss: 0.4744 - val_accuracy: 0.7932\n",
      "Epoch 41/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4834 - accuracy: 0.7701 - val_loss: 0.4907 - val_accuracy: 0.7804\n",
      "Epoch 42/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4831 - accuracy: 0.7771 - val_loss: 0.4788 - val_accuracy: 0.7846\n",
      "Epoch 43/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4816 - accuracy: 0.7760 - val_loss: 0.4662 - val_accuracy: 0.7996\n",
      "Epoch 44/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4846 - accuracy: 0.7723 - val_loss: 0.4686 - val_accuracy: 0.7910\n",
      "Epoch 45/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4822 - accuracy: 0.7696 - val_loss: 0.4716 - val_accuracy: 0.7889\n",
      "Epoch 46/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4840 - accuracy: 0.7659 - val_loss: 0.4668 - val_accuracy: 0.7932\n",
      "Epoch 47/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4818 - accuracy: 0.7749 - val_loss: 0.4716 - val_accuracy: 0.7932\n",
      "Epoch 48/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4822 - accuracy: 0.7691 - val_loss: 0.4673 - val_accuracy: 0.8017\n",
      "accuracy: 80.17%\n",
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_84 (LSTM)               (None, 1, 50)             11400     \n",
      "_________________________________________________________________\n",
      "lstm_85 (LSTM)               (None, 27)                8424      \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 1)                 28        \n",
      "=================================================================\n",
      "Total params: 19,852\n",
      "Trainable params: 19,852\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/48\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.6481 - accuracy: 0.6421WARNING:tensorflow:Callbacks method `on_test_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_begin` time: 0.0010s). Check your callbacks.\n",
      "WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.6481 - accuracy: 0.6421 - val_loss: 0.5417 - val_accuracy: 0.7271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7339 - val_loss: 0.5509 - val_accuracy: 0.7122\n",
      "Epoch 3/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5139 - accuracy: 0.7563 - val_loss: 0.5153 - val_accuracy: 0.7761\n",
      "Epoch 4/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5156 - accuracy: 0.7541 - val_loss: 0.4936 - val_accuracy: 0.7825\n",
      "Epoch 5/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5091 - accuracy: 0.7579 - val_loss: 0.4856 - val_accuracy: 0.7910\n",
      "Epoch 6/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5065 - accuracy: 0.7632 - val_loss: 0.4835 - val_accuracy: 0.7974\n",
      "Epoch 7/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5062 - accuracy: 0.7611 - val_loss: 0.4963 - val_accuracy: 0.7740\n",
      "Epoch 8/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5053 - accuracy: 0.7611 - val_loss: 0.4807 - val_accuracy: 0.7932\n",
      "Epoch 9/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5062 - accuracy: 0.7632 - val_loss: 0.4896 - val_accuracy: 0.7825\n",
      "Epoch 10/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5039 - accuracy: 0.7605 - val_loss: 0.4794 - val_accuracy: 0.7953\n",
      "Epoch 11/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5016 - accuracy: 0.7659 - val_loss: 0.4761 - val_accuracy: 0.7953\n",
      "Epoch 12/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5006 - accuracy: 0.7643 - val_loss: 0.4791 - val_accuracy: 0.7846\n",
      "Epoch 13/48\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4995 - accuracy: 0.7621 - val_loss: 0.4919 - val_accuracy: 0.7761\n",
      "Epoch 14/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5017 - accuracy: 0.7579 - val_loss: 0.4725 - val_accuracy: 0.8017\n",
      "Epoch 15/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4966 - accuracy: 0.7589 - val_loss: 0.4745 - val_accuracy: 0.7996\n",
      "Epoch 16/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4950 - accuracy: 0.7627 - val_loss: 0.4706 - val_accuracy: 0.7996\n",
      "Epoch 17/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4950 - accuracy: 0.7685 - val_loss: 0.4925 - val_accuracy: 0.7676\n",
      "Epoch 18/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4934 - accuracy: 0.7627 - val_loss: 0.4738 - val_accuracy: 0.7889\n",
      "Epoch 19/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4921 - accuracy: 0.7680 - val_loss: 0.4673 - val_accuracy: 0.7974\n",
      "Epoch 20/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4923 - accuracy: 0.7616 - val_loss: 0.4662 - val_accuracy: 0.8017\n",
      "Epoch 21/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4910 - accuracy: 0.7653 - val_loss: 0.4667 - val_accuracy: 0.7932\n",
      "Epoch 22/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4895 - accuracy: 0.7685 - val_loss: 0.4736 - val_accuracy: 0.7974\n",
      "Epoch 23/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4869 - accuracy: 0.7685 - val_loss: 0.4714 - val_accuracy: 0.7889\n",
      "Epoch 24/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4905 - accuracy: 0.7637 - val_loss: 0.5081 - val_accuracy: 0.7633\n",
      "Epoch 25/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4895 - accuracy: 0.7659 - val_loss: 0.4665 - val_accuracy: 0.7974\n",
      "Epoch 26/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4855 - accuracy: 0.7680 - val_loss: 0.4626 - val_accuracy: 0.7953\n",
      "Epoch 27/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4883 - accuracy: 0.7685 - val_loss: 0.4668 - val_accuracy: 0.7932\n",
      "Epoch 28/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4862 - accuracy: 0.7728 - val_loss: 0.4773 - val_accuracy: 0.7846\n",
      "Epoch 29/48\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4875 - accuracy: 0.7680 - val_loss: 0.4660 - val_accuracy: 0.7974\n",
      "Epoch 30/48\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4848 - accuracy: 0.7691 - val_loss: 0.4873 - val_accuracy: 0.7825\n",
      "Epoch 31/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4872 - accuracy: 0.7712 - val_loss: 0.4647 - val_accuracy: 0.7974\n",
      "Epoch 32/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4872 - accuracy: 0.7680 - val_loss: 0.4686 - val_accuracy: 0.7996\n",
      "Epoch 33/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4842 - accuracy: 0.7765 - val_loss: 0.4716 - val_accuracy: 0.7868\n",
      "Epoch 34/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4837 - accuracy: 0.7701 - val_loss: 0.4681 - val_accuracy: 0.7974\n",
      "Epoch 35/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4844 - accuracy: 0.7723 - val_loss: 0.4739 - val_accuracy: 0.7846\n",
      "Epoch 36/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4843 - accuracy: 0.7723 - val_loss: 0.4842 - val_accuracy: 0.7825\n",
      "Epoch 37/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4836 - accuracy: 0.7744 - val_loss: 0.4656 - val_accuracy: 0.8017\n",
      "Epoch 38/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4822 - accuracy: 0.7701 - val_loss: 0.4663 - val_accuracy: 0.8017\n",
      "Epoch 39/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4847 - accuracy: 0.7680 - val_loss: 0.4697 - val_accuracy: 0.7996\n",
      "Epoch 40/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4845 - accuracy: 0.7669 - val_loss: 0.4654 - val_accuracy: 0.7996\n",
      "Epoch 41/48\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4848 - accuracy: 0.7669 - val_loss: 0.4691 - val_accuracy: 0.7974\n",
      "Epoch 42/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4851 - accuracy: 0.7728 - val_loss: 0.4944 - val_accuracy: 0.7676\n",
      "Epoch 43/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4839 - accuracy: 0.7696 - val_loss: 0.4806 - val_accuracy: 0.7846\n",
      "Epoch 44/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4842 - accuracy: 0.7707 - val_loss: 0.4640 - val_accuracy: 0.8081\n",
      "Epoch 45/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4828 - accuracy: 0.7685 - val_loss: 0.4641 - val_accuracy: 0.8017\n",
      "Epoch 46/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4814 - accuracy: 0.7701 - val_loss: 0.4638 - val_accuracy: 0.8060\n",
      "Epoch 47/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4843 - accuracy: 0.7691 - val_loss: 0.4771 - val_accuracy: 0.7868\n",
      "Epoch 48/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4808 - accuracy: 0.7685 - val_loss: 0.5063 - val_accuracy: 0.7591\n",
      "accuracy: 75.91%\n",
      "Model: \"sequential_43\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_86 (LSTM)               (None, 1, 50)             11400     \n",
      "_________________________________________________________________\n",
      "lstm_87 (LSTM)               (None, 27)                8424      \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 1)                 28        \n",
      "=================================================================\n",
      "Total params: 19,852\n",
      "Trainable params: 19,852\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/48\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.6489 - accuracy: 0.6443 - val_loss: 0.5403 - val_accuracy: 0.7548\n",
      "Epoch 2/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5249 - accuracy: 0.7424 - val_loss: 0.5027 - val_accuracy: 0.7719\n",
      "Epoch 3/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5154 - accuracy: 0.7573 - val_loss: 0.4886 - val_accuracy: 0.7868\n",
      "Epoch 4/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5094 - accuracy: 0.7552 - val_loss: 0.4853 - val_accuracy: 0.7889\n",
      "Epoch 5/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5103 - accuracy: 0.7557 - val_loss: 0.5003 - val_accuracy: 0.7612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5046 - accuracy: 0.7664 - val_loss: 0.4922 - val_accuracy: 0.7783\n",
      "Epoch 7/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5038 - accuracy: 0.7568 - val_loss: 0.4940 - val_accuracy: 0.7783\n",
      "Epoch 8/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5035 - accuracy: 0.7659 - val_loss: 0.5017 - val_accuracy: 0.7548\n",
      "Epoch 9/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5021 - accuracy: 0.7632 - val_loss: 0.4809 - val_accuracy: 0.7910\n",
      "Epoch 10/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5006 - accuracy: 0.7648 - val_loss: 0.4741 - val_accuracy: 0.7996\n",
      "Epoch 11/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5004 - accuracy: 0.7659 - val_loss: 0.4745 - val_accuracy: 0.7953\n",
      "Epoch 12/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4982 - accuracy: 0.7632 - val_loss: 0.4807 - val_accuracy: 0.7868\n",
      "Epoch 13/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4976 - accuracy: 0.7685 - val_loss: 0.4705 - val_accuracy: 0.8038\n",
      "Epoch 14/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4945 - accuracy: 0.7584 - val_loss: 0.4792 - val_accuracy: 0.7868\n",
      "Epoch 15/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4938 - accuracy: 0.7643 - val_loss: 0.4833 - val_accuracy: 0.7868\n",
      "Epoch 16/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4919 - accuracy: 0.7648 - val_loss: 0.4674 - val_accuracy: 0.8017\n",
      "Epoch 17/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4908 - accuracy: 0.7653 - val_loss: 0.4711 - val_accuracy: 0.7974\n",
      "Epoch 18/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4914 - accuracy: 0.7568 - val_loss: 0.4709 - val_accuracy: 0.7932\n",
      "Epoch 19/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4889 - accuracy: 0.7675 - val_loss: 0.4699 - val_accuracy: 0.7953\n",
      "Epoch 20/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4908 - accuracy: 0.7659 - val_loss: 0.4649 - val_accuracy: 0.7996\n",
      "Epoch 21/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4898 - accuracy: 0.7739 - val_loss: 0.4767 - val_accuracy: 0.7846\n",
      "Epoch 22/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4896 - accuracy: 0.7579 - val_loss: 0.4643 - val_accuracy: 0.7974\n",
      "Epoch 23/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4889 - accuracy: 0.7675 - val_loss: 0.4744 - val_accuracy: 0.7932\n",
      "Epoch 24/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4867 - accuracy: 0.7653 - val_loss: 0.4927 - val_accuracy: 0.7697\n",
      "Epoch 25/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4876 - accuracy: 0.7669 - val_loss: 0.4788 - val_accuracy: 0.7910\n",
      "Epoch 26/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4881 - accuracy: 0.7691 - val_loss: 0.4690 - val_accuracy: 0.7910\n",
      "Epoch 27/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4869 - accuracy: 0.7680 - val_loss: 0.4662 - val_accuracy: 0.7953\n",
      "Epoch 28/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4832 - accuracy: 0.7739 - val_loss: 0.4635 - val_accuracy: 0.8017\n",
      "Epoch 29/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4878 - accuracy: 0.7707 - val_loss: 0.4680 - val_accuracy: 0.7996\n",
      "Epoch 30/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4836 - accuracy: 0.7739 - val_loss: 0.4728 - val_accuracy: 0.7932\n",
      "Epoch 31/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4862 - accuracy: 0.7664 - val_loss: 0.4641 - val_accuracy: 0.7996\n",
      "Epoch 32/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4844 - accuracy: 0.7755 - val_loss: 0.4761 - val_accuracy: 0.7889\n",
      "Epoch 33/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4854 - accuracy: 0.7701 - val_loss: 0.4740 - val_accuracy: 0.7974\n",
      "Epoch 34/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4837 - accuracy: 0.7723 - val_loss: 0.4678 - val_accuracy: 0.8081\n",
      "Epoch 35/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4871 - accuracy: 0.7733 - val_loss: 0.4721 - val_accuracy: 0.7974\n",
      "Epoch 36/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4851 - accuracy: 0.7659 - val_loss: 0.4756 - val_accuracy: 0.7910\n",
      "Epoch 37/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4825 - accuracy: 0.7691 - val_loss: 0.4673 - val_accuracy: 0.7974\n",
      "Epoch 38/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4847 - accuracy: 0.7739 - val_loss: 0.4667 - val_accuracy: 0.7974\n",
      "Epoch 39/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4821 - accuracy: 0.7696 - val_loss: 0.4651 - val_accuracy: 0.7974\n",
      "Epoch 40/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4844 - accuracy: 0.7675 - val_loss: 0.4804 - val_accuracy: 0.7868\n",
      "Epoch 41/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4833 - accuracy: 0.7653 - val_loss: 0.4691 - val_accuracy: 0.7996\n",
      "Epoch 42/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4846 - accuracy: 0.7675 - val_loss: 0.4668 - val_accuracy: 0.8017\n",
      "Epoch 43/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4832 - accuracy: 0.7733 - val_loss: 0.4706 - val_accuracy: 0.7953\n",
      "Epoch 44/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4828 - accuracy: 0.7701 - val_loss: 0.4736 - val_accuracy: 0.7974\n",
      "Epoch 45/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4809 - accuracy: 0.7680 - val_loss: 0.4649 - val_accuracy: 0.7996\n",
      "Epoch 46/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4819 - accuracy: 0.7739 - val_loss: 0.4822 - val_accuracy: 0.7932\n",
      "Epoch 47/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4805 - accuracy: 0.7691 - val_loss: 0.4764 - val_accuracy: 0.7889\n",
      "Epoch 48/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4819 - accuracy: 0.7691 - val_loss: 0.4720 - val_accuracy: 0.7932\n",
      "accuracy: 79.32%\n",
      "Model: \"sequential_44\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_88 (LSTM)               (None, 1, 50)             11400     \n",
      "_________________________________________________________________\n",
      "lstm_89 (LSTM)               (None, 27)                8424      \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 1)                 28        \n",
      "=================================================================\n",
      "Total params: 19,852\n",
      "Trainable params: 19,852\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/48\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.6560 - accuracy: 0.6427 - val_loss: 0.5524 - val_accuracy: 0.7420\n",
      "Epoch 2/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5302 - accuracy: 0.7424 - val_loss: 0.5172 - val_accuracy: 0.7399\n",
      "Epoch 3/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5122 - accuracy: 0.7477 - val_loss: 0.4892 - val_accuracy: 0.7783\n",
      "Epoch 4/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5074 - accuracy: 0.7637 - val_loss: 0.4838 - val_accuracy: 0.7868\n",
      "Epoch 5/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5064 - accuracy: 0.7637 - val_loss: 0.4833 - val_accuracy: 0.7868\n",
      "Epoch 6/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5031 - accuracy: 0.7547 - val_loss: 0.4790 - val_accuracy: 0.7932\n",
      "Epoch 7/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5013 - accuracy: 0.7712 - val_loss: 0.4777 - val_accuracy: 0.7889\n",
      "Epoch 8/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5011 - accuracy: 0.7653 - val_loss: 0.4800 - val_accuracy: 0.7825\n",
      "Epoch 9/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4992 - accuracy: 0.7595 - val_loss: 0.4882 - val_accuracy: 0.7783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4972 - accuracy: 0.7685 - val_loss: 0.4923 - val_accuracy: 0.7846\n",
      "Epoch 11/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4966 - accuracy: 0.7696 - val_loss: 0.4707 - val_accuracy: 0.7996\n",
      "Epoch 12/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4965 - accuracy: 0.7552 - val_loss: 0.4762 - val_accuracy: 0.7889\n",
      "Epoch 13/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4947 - accuracy: 0.7659 - val_loss: 0.4677 - val_accuracy: 0.7974\n",
      "Epoch 14/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4937 - accuracy: 0.7696 - val_loss: 0.4680 - val_accuracy: 0.7996\n",
      "Epoch 15/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4926 - accuracy: 0.7691 - val_loss: 0.4829 - val_accuracy: 0.7889\n",
      "Epoch 16/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4916 - accuracy: 0.7648 - val_loss: 0.4648 - val_accuracy: 0.7974\n",
      "Epoch 17/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4896 - accuracy: 0.7723 - val_loss: 0.4661 - val_accuracy: 0.8017\n",
      "Epoch 18/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4905 - accuracy: 0.7611 - val_loss: 0.4654 - val_accuracy: 0.7996\n",
      "Epoch 19/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4908 - accuracy: 0.7680 - val_loss: 0.4675 - val_accuracy: 0.8060\n",
      "Epoch 20/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4910 - accuracy: 0.7653 - val_loss: 0.4683 - val_accuracy: 0.7974\n",
      "Epoch 21/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4906 - accuracy: 0.7669 - val_loss: 0.4680 - val_accuracy: 0.7953\n",
      "Epoch 22/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4886 - accuracy: 0.7696 - val_loss: 0.4655 - val_accuracy: 0.7996\n",
      "Epoch 23/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4888 - accuracy: 0.7749 - val_loss: 0.4725 - val_accuracy: 0.7889\n",
      "Epoch 24/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4876 - accuracy: 0.7659 - val_loss: 0.4861 - val_accuracy: 0.7825\n",
      "Epoch 25/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4881 - accuracy: 0.7728 - val_loss: 0.4640 - val_accuracy: 0.8038\n",
      "Epoch 26/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4875 - accuracy: 0.7691 - val_loss: 0.4669 - val_accuracy: 0.7953\n",
      "Epoch 27/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4853 - accuracy: 0.7691 - val_loss: 0.4665 - val_accuracy: 0.7953\n",
      "Epoch 28/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4871 - accuracy: 0.7691 - val_loss: 0.4634 - val_accuracy: 0.8038\n",
      "Epoch 29/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4865 - accuracy: 0.7664 - val_loss: 0.4646 - val_accuracy: 0.7953\n",
      "Epoch 30/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4848 - accuracy: 0.7696 - val_loss: 0.4671 - val_accuracy: 0.7974\n",
      "Epoch 31/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4851 - accuracy: 0.7648 - val_loss: 0.4659 - val_accuracy: 0.8102\n",
      "Epoch 32/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4854 - accuracy: 0.7707 - val_loss: 0.4639 - val_accuracy: 0.7974\n",
      "Epoch 33/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4846 - accuracy: 0.7627 - val_loss: 0.4648 - val_accuracy: 0.8017\n",
      "Epoch 34/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4869 - accuracy: 0.7707 - val_loss: 0.4710 - val_accuracy: 0.7889\n",
      "Epoch 35/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4858 - accuracy: 0.7685 - val_loss: 0.4743 - val_accuracy: 0.7910\n",
      "Epoch 36/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4849 - accuracy: 0.7675 - val_loss: 0.4705 - val_accuracy: 0.7953\n",
      "Epoch 37/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4844 - accuracy: 0.7680 - val_loss: 0.4644 - val_accuracy: 0.7974\n",
      "Epoch 38/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4852 - accuracy: 0.7632 - val_loss: 0.4643 - val_accuracy: 0.7932\n",
      "Epoch 39/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4833 - accuracy: 0.7701 - val_loss: 0.4635 - val_accuracy: 0.7953\n",
      "Epoch 40/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4847 - accuracy: 0.7739 - val_loss: 0.4645 - val_accuracy: 0.7953\n",
      "Epoch 41/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4851 - accuracy: 0.7680 - val_loss: 0.4650 - val_accuracy: 0.8038\n",
      "Epoch 42/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4836 - accuracy: 0.7701 - val_loss: 0.4652 - val_accuracy: 0.7974\n",
      "Epoch 43/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4827 - accuracy: 0.7749 - val_loss: 0.4634 - val_accuracy: 0.7974\n",
      "Epoch 44/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4860 - accuracy: 0.7717 - val_loss: 0.4654 - val_accuracy: 0.7974\n",
      "Epoch 45/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4829 - accuracy: 0.7680 - val_loss: 0.4656 - val_accuracy: 0.7974\n",
      "Epoch 46/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4842 - accuracy: 0.7712 - val_loss: 0.4649 - val_accuracy: 0.7974\n",
      "Epoch 47/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4831 - accuracy: 0.7733 - val_loss: 0.4700 - val_accuracy: 0.7996\n",
      "Epoch 48/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4818 - accuracy: 0.7712 - val_loss: 0.4660 - val_accuracy: 0.7953\n",
      "accuracy: 79.53%\n",
      "Model: \"sequential_45\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_90 (LSTM)               (None, 1, 50)             11400     \n",
      "_________________________________________________________________\n",
      "lstm_91 (LSTM)               (None, 27)                8424      \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 1)                 28        \n",
      "=================================================================\n",
      "Total params: 19,852\n",
      "Trainable params: 19,852\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/48\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6545 - accuracy: 0.6272 - val_loss: 0.5482 - val_accuracy: 0.7271\n",
      "Epoch 2/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5349 - accuracy: 0.7371 - val_loss: 0.5093 - val_accuracy: 0.7484\n",
      "Epoch 3/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5167 - accuracy: 0.7477 - val_loss: 0.5002 - val_accuracy: 0.7655\n",
      "Epoch 4/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5119 - accuracy: 0.7461 - val_loss: 0.4953 - val_accuracy: 0.7761\n",
      "Epoch 5/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5082 - accuracy: 0.7557 - val_loss: 0.5020 - val_accuracy: 0.7719\n",
      "Epoch 6/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5084 - accuracy: 0.7525 - val_loss: 0.4816 - val_accuracy: 0.7953\n",
      "Epoch 7/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5045 - accuracy: 0.7643 - val_loss: 0.4791 - val_accuracy: 0.7910\n",
      "Epoch 8/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5033 - accuracy: 0.7611 - val_loss: 0.4796 - val_accuracy: 0.7910\n",
      "Epoch 9/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5041 - accuracy: 0.7627 - val_loss: 0.4782 - val_accuracy: 0.7868\n",
      "Epoch 10/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5030 - accuracy: 0.7557 - val_loss: 0.4839 - val_accuracy: 0.7846\n",
      "Epoch 11/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4985 - accuracy: 0.7691 - val_loss: 0.4768 - val_accuracy: 0.7932\n",
      "Epoch 12/48\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4990 - accuracy: 0.7648 - val_loss: 0.4748 - val_accuracy: 0.8017\n",
      "Epoch 13/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4986 - accuracy: 0.7648 - val_loss: 0.4795 - val_accuracy: 0.7846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4989 - accuracy: 0.7653 - val_loss: 0.4715 - val_accuracy: 0.7974\n",
      "Epoch 15/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4963 - accuracy: 0.7621 - val_loss: 0.4696 - val_accuracy: 0.7996\n",
      "Epoch 16/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4954 - accuracy: 0.7605 - val_loss: 0.4718 - val_accuracy: 0.7996\n",
      "Epoch 17/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4935 - accuracy: 0.7680 - val_loss: 0.4684 - val_accuracy: 0.7974\n",
      "Epoch 18/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4931 - accuracy: 0.7675 - val_loss: 0.4972 - val_accuracy: 0.7633\n",
      "Epoch 19/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4929 - accuracy: 0.7680 - val_loss: 0.4801 - val_accuracy: 0.7825\n",
      "Epoch 20/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4913 - accuracy: 0.7632 - val_loss: 0.4727 - val_accuracy: 0.7910\n",
      "Epoch 21/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4881 - accuracy: 0.7669 - val_loss: 0.4787 - val_accuracy: 0.7868\n",
      "Epoch 22/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4886 - accuracy: 0.7696 - val_loss: 0.4777 - val_accuracy: 0.7889\n",
      "Epoch 23/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4893 - accuracy: 0.7648 - val_loss: 0.4671 - val_accuracy: 0.7996\n",
      "Epoch 24/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4870 - accuracy: 0.7637 - val_loss: 0.4684 - val_accuracy: 0.7932\n",
      "Epoch 25/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4863 - accuracy: 0.7712 - val_loss: 0.4849 - val_accuracy: 0.7825\n",
      "Epoch 26/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4873 - accuracy: 0.7648 - val_loss: 0.4756 - val_accuracy: 0.7932\n",
      "Epoch 27/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4854 - accuracy: 0.7707 - val_loss: 0.4649 - val_accuracy: 0.7974\n",
      "Epoch 28/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4856 - accuracy: 0.7664 - val_loss: 0.4652 - val_accuracy: 0.7974\n",
      "Epoch 29/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4856 - accuracy: 0.7701 - val_loss: 0.4683 - val_accuracy: 0.7932\n",
      "Epoch 30/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4855 - accuracy: 0.7728 - val_loss: 0.4678 - val_accuracy: 0.7953\n",
      "Epoch 31/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4867 - accuracy: 0.7664 - val_loss: 0.4661 - val_accuracy: 0.7996\n",
      "Epoch 32/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4855 - accuracy: 0.7701 - val_loss: 0.4704 - val_accuracy: 0.7974\n",
      "Epoch 33/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4854 - accuracy: 0.7675 - val_loss: 0.4647 - val_accuracy: 0.7953\n",
      "Epoch 34/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4852 - accuracy: 0.7701 - val_loss: 0.4639 - val_accuracy: 0.7996\n",
      "Epoch 35/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4844 - accuracy: 0.7707 - val_loss: 0.4807 - val_accuracy: 0.7868\n",
      "Epoch 36/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4855 - accuracy: 0.7627 - val_loss: 0.4655 - val_accuracy: 0.7953\n",
      "Epoch 37/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4831 - accuracy: 0.7659 - val_loss: 0.4733 - val_accuracy: 0.7932\n",
      "Epoch 38/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4839 - accuracy: 0.7728 - val_loss: 0.4650 - val_accuracy: 0.7910\n",
      "Epoch 39/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4839 - accuracy: 0.7723 - val_loss: 0.4692 - val_accuracy: 0.7974\n",
      "Epoch 40/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4837 - accuracy: 0.7707 - val_loss: 0.4708 - val_accuracy: 0.7974\n",
      "Epoch 41/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4843 - accuracy: 0.7680 - val_loss: 0.4756 - val_accuracy: 0.7910\n",
      "Epoch 42/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4839 - accuracy: 0.7744 - val_loss: 0.4757 - val_accuracy: 0.7889\n",
      "Epoch 43/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4840 - accuracy: 0.7712 - val_loss: 0.4818 - val_accuracy: 0.7846\n",
      "Epoch 44/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4814 - accuracy: 0.7744 - val_loss: 0.4647 - val_accuracy: 0.7974\n",
      "Epoch 45/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4813 - accuracy: 0.7739 - val_loss: 0.4665 - val_accuracy: 0.8017\n",
      "Epoch 46/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4829 - accuracy: 0.7680 - val_loss: 0.4656 - val_accuracy: 0.7953\n",
      "Epoch 47/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4829 - accuracy: 0.7675 - val_loss: 0.4663 - val_accuracy: 0.7953\n",
      "Epoch 48/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4842 - accuracy: 0.7685 - val_loss: 0.4744 - val_accuracy: 0.7889\n",
      "accuracy: 78.89%\n",
      "Model: \"sequential_46\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_92 (LSTM)               (None, 1, 50)             11400     \n",
      "_________________________________________________________________\n",
      "lstm_93 (LSTM)               (None, 27)                8424      \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 1)                 28        \n",
      "=================================================================\n",
      "Total params: 19,852\n",
      "Trainable params: 19,852\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/48\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6479 - accuracy: 0.6453 - val_loss: 0.5350 - val_accuracy: 0.7079\n",
      "Epoch 2/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5297 - accuracy: 0.7403 - val_loss: 0.5048 - val_accuracy: 0.7783\n",
      "Epoch 3/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5170 - accuracy: 0.7499 - val_loss: 0.4918 - val_accuracy: 0.7825\n",
      "Epoch 4/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5115 - accuracy: 0.7509 - val_loss: 0.5062 - val_accuracy: 0.7676\n",
      "Epoch 5/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5078 - accuracy: 0.7637 - val_loss: 0.4935 - val_accuracy: 0.7783\n",
      "Epoch 6/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5069 - accuracy: 0.7557 - val_loss: 0.4824 - val_accuracy: 0.7889\n",
      "Epoch 7/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5047 - accuracy: 0.7669 - val_loss: 0.5063 - val_accuracy: 0.7612\n",
      "Epoch 8/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5052 - accuracy: 0.7531 - val_loss: 0.4787 - val_accuracy: 0.7996\n",
      "Epoch 9/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5003 - accuracy: 0.7648 - val_loss: 0.4828 - val_accuracy: 0.7846\n",
      "Epoch 10/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4983 - accuracy: 0.7653 - val_loss: 0.4737 - val_accuracy: 0.7932\n",
      "Epoch 11/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4989 - accuracy: 0.7605 - val_loss: 0.4759 - val_accuracy: 0.7932\n",
      "Epoch 12/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4965 - accuracy: 0.7616 - val_loss: 0.4758 - val_accuracy: 0.7974\n",
      "Epoch 13/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4953 - accuracy: 0.7605 - val_loss: 0.4979 - val_accuracy: 0.7697\n",
      "Epoch 14/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4982 - accuracy: 0.7675 - val_loss: 0.4689 - val_accuracy: 0.8017\n",
      "Epoch 15/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4951 - accuracy: 0.7707 - val_loss: 0.4765 - val_accuracy: 0.7953\n",
      "Epoch 16/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4939 - accuracy: 0.7680 - val_loss: 0.4739 - val_accuracy: 0.7932\n",
      "Epoch 17/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4930 - accuracy: 0.7595 - val_loss: 0.4760 - val_accuracy: 0.7846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4909 - accuracy: 0.7659 - val_loss: 0.4750 - val_accuracy: 0.7825\n",
      "Epoch 19/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4905 - accuracy: 0.7696 - val_loss: 0.4664 - val_accuracy: 0.7996\n",
      "Epoch 20/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4885 - accuracy: 0.7675 - val_loss: 0.4720 - val_accuracy: 0.7953\n",
      "Epoch 21/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4898 - accuracy: 0.7653 - val_loss: 0.4738 - val_accuracy: 0.7910\n",
      "Epoch 22/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4898 - accuracy: 0.7680 - val_loss: 0.4690 - val_accuracy: 0.7932\n",
      "Epoch 23/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4882 - accuracy: 0.7659 - val_loss: 0.4680 - val_accuracy: 0.7953\n",
      "Epoch 24/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4884 - accuracy: 0.7701 - val_loss: 0.4755 - val_accuracy: 0.7910\n",
      "Epoch 25/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4905 - accuracy: 0.7696 - val_loss: 0.4671 - val_accuracy: 0.7932\n",
      "Epoch 26/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4868 - accuracy: 0.7685 - val_loss: 0.4676 - val_accuracy: 0.8017\n",
      "Epoch 27/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4867 - accuracy: 0.7659 - val_loss: 0.4665 - val_accuracy: 0.7953\n",
      "Epoch 28/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4857 - accuracy: 0.7696 - val_loss: 0.4708 - val_accuracy: 0.7889\n",
      "Epoch 29/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4849 - accuracy: 0.7701 - val_loss: 0.4660 - val_accuracy: 0.7996\n",
      "Epoch 30/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4840 - accuracy: 0.7701 - val_loss: 0.4675 - val_accuracy: 0.7996\n",
      "Epoch 31/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4875 - accuracy: 0.7675 - val_loss: 0.4741 - val_accuracy: 0.7889\n",
      "Epoch 32/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4847 - accuracy: 0.7728 - val_loss: 0.4867 - val_accuracy: 0.7804\n",
      "Epoch 33/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4844 - accuracy: 0.7632 - val_loss: 0.4737 - val_accuracy: 0.7868\n",
      "Epoch 34/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4828 - accuracy: 0.7691 - val_loss: 0.4911 - val_accuracy: 0.7719\n",
      "Epoch 35/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4847 - accuracy: 0.7680 - val_loss: 0.4683 - val_accuracy: 0.7996\n",
      "Epoch 36/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4833 - accuracy: 0.7696 - val_loss: 0.4667 - val_accuracy: 0.8017\n",
      "Epoch 37/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4854 - accuracy: 0.7637 - val_loss: 0.4664 - val_accuracy: 0.7974\n",
      "Epoch 38/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4838 - accuracy: 0.7675 - val_loss: 0.4667 - val_accuracy: 0.7953\n",
      "Epoch 39/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4870 - accuracy: 0.7632 - val_loss: 0.4739 - val_accuracy: 0.7910\n",
      "Epoch 40/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4868 - accuracy: 0.7739 - val_loss: 0.4718 - val_accuracy: 0.7953\n",
      "Epoch 41/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4842 - accuracy: 0.7691 - val_loss: 0.4717 - val_accuracy: 0.7889\n",
      "Epoch 42/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4849 - accuracy: 0.7723 - val_loss: 0.4690 - val_accuracy: 0.7953\n",
      "Epoch 43/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4844 - accuracy: 0.7739 - val_loss: 0.4657 - val_accuracy: 0.7996\n",
      "Epoch 44/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4840 - accuracy: 0.7723 - val_loss: 0.4779 - val_accuracy: 0.7868\n",
      "Epoch 45/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4836 - accuracy: 0.7728 - val_loss: 0.4683 - val_accuracy: 0.7953\n",
      "Epoch 46/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4828 - accuracy: 0.7717 - val_loss: 0.4669 - val_accuracy: 0.7996\n",
      "Epoch 47/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4815 - accuracy: 0.7771 - val_loss: 0.4654 - val_accuracy: 0.7974\n",
      "Epoch 48/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4846 - accuracy: 0.7685 - val_loss: 0.4660 - val_accuracy: 0.7996\n",
      "accuracy: 79.96%\n",
      "Model: \"sequential_47\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_94 (LSTM)               (None, 1, 50)             11400     \n",
      "_________________________________________________________________\n",
      "lstm_95 (LSTM)               (None, 27)                8424      \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 1)                 28        \n",
      "=================================================================\n",
      "Total params: 19,852\n",
      "Trainable params: 19,852\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/48\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6428 - accuracy: 0.6587 - val_loss: 0.5456 - val_accuracy: 0.7335\n",
      "Epoch 2/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5317 - accuracy: 0.7285 - val_loss: 0.5145 - val_accuracy: 0.7441\n",
      "Epoch 3/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5148 - accuracy: 0.7557 - val_loss: 0.5028 - val_accuracy: 0.7612\n",
      "Epoch 4/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5095 - accuracy: 0.7573 - val_loss: 0.4859 - val_accuracy: 0.7910\n",
      "Epoch 5/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5083 - accuracy: 0.7595 - val_loss: 0.5061 - val_accuracy: 0.7591\n",
      "Epoch 6/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5077 - accuracy: 0.7605 - val_loss: 0.5047 - val_accuracy: 0.7527\n",
      "Epoch 7/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5068 - accuracy: 0.7573 - val_loss: 0.4799 - val_accuracy: 0.7889\n",
      "Epoch 8/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5057 - accuracy: 0.7579 - val_loss: 0.4795 - val_accuracy: 0.7846\n",
      "Epoch 9/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5018 - accuracy: 0.7573 - val_loss: 0.4778 - val_accuracy: 0.7953\n",
      "Epoch 10/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5009 - accuracy: 0.7659 - val_loss: 0.4794 - val_accuracy: 0.7910\n",
      "Epoch 11/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5031 - accuracy: 0.7648 - val_loss: 0.4730 - val_accuracy: 0.8017\n",
      "Epoch 12/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4993 - accuracy: 0.7643 - val_loss: 0.4869 - val_accuracy: 0.7783\n",
      "Epoch 13/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5003 - accuracy: 0.7659 - val_loss: 0.4711 - val_accuracy: 0.7953\n",
      "Epoch 14/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4934 - accuracy: 0.7621 - val_loss: 0.4899 - val_accuracy: 0.7697\n",
      "Epoch 15/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4937 - accuracy: 0.7648 - val_loss: 0.4683 - val_accuracy: 0.7974\n",
      "Epoch 16/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4928 - accuracy: 0.7675 - val_loss: 0.4674 - val_accuracy: 0.7974\n",
      "Epoch 17/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4906 - accuracy: 0.7696 - val_loss: 0.5005 - val_accuracy: 0.7676\n",
      "Epoch 18/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4886 - accuracy: 0.7632 - val_loss: 0.4645 - val_accuracy: 0.7953\n",
      "Epoch 19/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4896 - accuracy: 0.7701 - val_loss: 0.4680 - val_accuracy: 0.7953\n",
      "Epoch 20/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4882 - accuracy: 0.7712 - val_loss: 0.4678 - val_accuracy: 0.7953\n",
      "Epoch 21/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4880 - accuracy: 0.7680 - val_loss: 0.4658 - val_accuracy: 0.7974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4866 - accuracy: 0.7675 - val_loss: 0.4686 - val_accuracy: 0.7953\n",
      "Epoch 23/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4876 - accuracy: 0.7712 - val_loss: 0.4777 - val_accuracy: 0.7846\n",
      "Epoch 24/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4858 - accuracy: 0.7712 - val_loss: 0.4687 - val_accuracy: 0.7996\n",
      "Epoch 25/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4871 - accuracy: 0.7669 - val_loss: 0.4673 - val_accuracy: 0.7996\n",
      "Epoch 26/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4854 - accuracy: 0.7717 - val_loss: 0.4648 - val_accuracy: 0.7996\n",
      "Epoch 27/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4864 - accuracy: 0.7712 - val_loss: 0.4656 - val_accuracy: 0.7996\n",
      "Epoch 28/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4856 - accuracy: 0.7685 - val_loss: 0.4683 - val_accuracy: 0.7974\n",
      "Epoch 29/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4859 - accuracy: 0.7755 - val_loss: 0.4743 - val_accuracy: 0.7889\n",
      "Epoch 30/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4862 - accuracy: 0.7669 - val_loss: 0.4705 - val_accuracy: 0.7932\n",
      "Epoch 31/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4844 - accuracy: 0.7696 - val_loss: 0.4675 - val_accuracy: 0.7932\n",
      "Epoch 32/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4835 - accuracy: 0.7707 - val_loss: 0.4702 - val_accuracy: 0.7846\n",
      "Epoch 33/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4851 - accuracy: 0.7717 - val_loss: 0.4662 - val_accuracy: 0.7996\n",
      "Epoch 34/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4829 - accuracy: 0.7669 - val_loss: 0.4641 - val_accuracy: 0.7953\n",
      "Epoch 35/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4833 - accuracy: 0.7707 - val_loss: 0.4684 - val_accuracy: 0.7953\n",
      "Epoch 36/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4829 - accuracy: 0.7755 - val_loss: 0.4637 - val_accuracy: 0.7996\n",
      "Epoch 37/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4833 - accuracy: 0.7691 - val_loss: 0.4658 - val_accuracy: 0.8017\n",
      "Epoch 38/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4832 - accuracy: 0.7717 - val_loss: 0.4653 - val_accuracy: 0.7996\n",
      "Epoch 39/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4821 - accuracy: 0.7701 - val_loss: 0.4659 - val_accuracy: 0.8038\n",
      "Epoch 40/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4831 - accuracy: 0.7733 - val_loss: 0.4792 - val_accuracy: 0.7868\n",
      "Epoch 41/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4825 - accuracy: 0.7755 - val_loss: 0.5032 - val_accuracy: 0.7633\n",
      "Epoch 42/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4829 - accuracy: 0.7771 - val_loss: 0.4779 - val_accuracy: 0.7910\n",
      "Epoch 43/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4828 - accuracy: 0.7680 - val_loss: 0.4678 - val_accuracy: 0.7953\n",
      "Epoch 44/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4844 - accuracy: 0.7691 - val_loss: 0.4644 - val_accuracy: 0.7996\n",
      "Epoch 45/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4823 - accuracy: 0.7717 - val_loss: 0.4654 - val_accuracy: 0.7996\n",
      "Epoch 46/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4813 - accuracy: 0.7717 - val_loss: 0.4800 - val_accuracy: 0.7889\n",
      "Epoch 47/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4832 - accuracy: 0.7664 - val_loss: 0.4645 - val_accuracy: 0.8017\n",
      "Epoch 48/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4820 - accuracy: 0.7760 - val_loss: 0.4674 - val_accuracy: 0.7996\n",
      "accuracy: 79.96%\n",
      "Model: \"sequential_48\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_96 (LSTM)               (None, 1, 50)             11400     \n",
      "_________________________________________________________________\n",
      "lstm_97 (LSTM)               (None, 27)                8424      \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 1)                 28        \n",
      "=================================================================\n",
      "Total params: 19,852\n",
      "Trainable params: 19,852\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/48\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6618 - accuracy: 0.6304 - val_loss: 0.5490 - val_accuracy: 0.7441\n",
      "Epoch 2/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5296 - accuracy: 0.7397 - val_loss: 0.5004 - val_accuracy: 0.7591\n",
      "Epoch 3/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5142 - accuracy: 0.7541 - val_loss: 0.5051 - val_accuracy: 0.7548\n",
      "Epoch 4/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5107 - accuracy: 0.7621 - val_loss: 0.4881 - val_accuracy: 0.7889\n",
      "Epoch 5/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5094 - accuracy: 0.7616 - val_loss: 0.4956 - val_accuracy: 0.7825\n",
      "Epoch 6/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5075 - accuracy: 0.7584 - val_loss: 0.4853 - val_accuracy: 0.7889\n",
      "Epoch 7/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5041 - accuracy: 0.7573 - val_loss: 0.4839 - val_accuracy: 0.7932\n",
      "Epoch 8/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5031 - accuracy: 0.7637 - val_loss: 0.4823 - val_accuracy: 0.7910\n",
      "Epoch 9/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5023 - accuracy: 0.7621 - val_loss: 0.5091 - val_accuracy: 0.7527\n",
      "Epoch 10/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5017 - accuracy: 0.7643 - val_loss: 0.4912 - val_accuracy: 0.7783\n",
      "Epoch 11/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4984 - accuracy: 0.7675 - val_loss: 0.5643 - val_accuracy: 0.7164\n",
      "Epoch 12/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5017 - accuracy: 0.7557 - val_loss: 0.4773 - val_accuracy: 0.8038\n",
      "Epoch 13/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5023 - accuracy: 0.7605 - val_loss: 0.4775 - val_accuracy: 0.8038\n",
      "Epoch 14/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5006 - accuracy: 0.7680 - val_loss: 0.4775 - val_accuracy: 0.7910\n",
      "Epoch 15/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4995 - accuracy: 0.7632 - val_loss: 0.4757 - val_accuracy: 0.7953\n",
      "Epoch 16/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4988 - accuracy: 0.7552 - val_loss: 0.4889 - val_accuracy: 0.7783\n",
      "Epoch 17/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4979 - accuracy: 0.7669 - val_loss: 0.4739 - val_accuracy: 0.8038\n",
      "Epoch 18/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4934 - accuracy: 0.7595 - val_loss: 0.4861 - val_accuracy: 0.7783\n",
      "Epoch 19/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4959 - accuracy: 0.7584 - val_loss: 0.4950 - val_accuracy: 0.7697\n",
      "Epoch 20/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4958 - accuracy: 0.7595 - val_loss: 0.4784 - val_accuracy: 0.7846\n",
      "Epoch 21/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4950 - accuracy: 0.7707 - val_loss: 0.4833 - val_accuracy: 0.7783\n",
      "Epoch 22/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4938 - accuracy: 0.7600 - val_loss: 0.4711 - val_accuracy: 0.8081\n",
      "Epoch 23/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4927 - accuracy: 0.7643 - val_loss: 0.4713 - val_accuracy: 0.7996\n",
      "Epoch 24/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4933 - accuracy: 0.7637 - val_loss: 0.4901 - val_accuracy: 0.7719\n",
      "Epoch 25/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4907 - accuracy: 0.7664 - val_loss: 0.4774 - val_accuracy: 0.7868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4914 - accuracy: 0.7669 - val_loss: 0.4801 - val_accuracy: 0.7804\n",
      "Epoch 27/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4908 - accuracy: 0.7643 - val_loss: 0.4705 - val_accuracy: 0.8038\n",
      "Epoch 28/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4886 - accuracy: 0.7664 - val_loss: 0.4661 - val_accuracy: 0.7996\n",
      "Epoch 29/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4896 - accuracy: 0.7653 - val_loss: 0.4650 - val_accuracy: 0.7996\n",
      "Epoch 30/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4873 - accuracy: 0.7680 - val_loss: 0.4705 - val_accuracy: 0.7953\n",
      "Epoch 31/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4882 - accuracy: 0.7611 - val_loss: 0.4692 - val_accuracy: 0.7996\n",
      "Epoch 32/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4875 - accuracy: 0.7664 - val_loss: 0.4656 - val_accuracy: 0.8038\n",
      "Epoch 33/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4877 - accuracy: 0.7707 - val_loss: 0.4660 - val_accuracy: 0.7953\n",
      "Epoch 34/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4868 - accuracy: 0.7595 - val_loss: 0.4671 - val_accuracy: 0.8038\n",
      "Epoch 35/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4851 - accuracy: 0.7717 - val_loss: 0.4643 - val_accuracy: 0.7996\n",
      "Epoch 36/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4870 - accuracy: 0.7707 - val_loss: 0.4697 - val_accuracy: 0.7953\n",
      "Epoch 37/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4864 - accuracy: 0.7707 - val_loss: 0.4730 - val_accuracy: 0.7932\n",
      "Epoch 38/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4849 - accuracy: 0.7701 - val_loss: 0.4658 - val_accuracy: 0.7953\n",
      "Epoch 39/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4847 - accuracy: 0.7712 - val_loss: 0.4666 - val_accuracy: 0.7910\n",
      "Epoch 40/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4853 - accuracy: 0.7653 - val_loss: 0.4696 - val_accuracy: 0.7996\n",
      "Epoch 41/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4844 - accuracy: 0.7717 - val_loss: 0.4677 - val_accuracy: 0.7974\n",
      "Epoch 42/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4865 - accuracy: 0.7669 - val_loss: 0.4660 - val_accuracy: 0.8017\n",
      "Epoch 43/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4845 - accuracy: 0.7691 - val_loss: 0.4773 - val_accuracy: 0.7889\n",
      "Epoch 44/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4850 - accuracy: 0.7669 - val_loss: 0.4766 - val_accuracy: 0.7910\n",
      "Epoch 45/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4870 - accuracy: 0.7744 - val_loss: 0.4637 - val_accuracy: 0.7974\n",
      "Epoch 46/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4837 - accuracy: 0.7691 - val_loss: 0.4741 - val_accuracy: 0.7953\n",
      "Epoch 47/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4854 - accuracy: 0.7685 - val_loss: 0.4780 - val_accuracy: 0.7932\n",
      "Epoch 48/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4834 - accuracy: 0.7685 - val_loss: 0.4722 - val_accuracy: 0.7953\n",
      "accuracy: 79.53%\n",
      "Model: \"sequential_49\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_98 (LSTM)               (None, 1, 50)             11400     \n",
      "_________________________________________________________________\n",
      "lstm_99 (LSTM)               (None, 27)                8424      \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 1)                 28        \n",
      "=================================================================\n",
      "Total params: 19,852\n",
      "Trainable params: 19,852\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/48\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.6649 - accuracy: 0.6448 - val_loss: 0.5662 - val_accuracy: 0.7143\n",
      "Epoch 2/48\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5360 - accuracy: 0.7328 - val_loss: 0.5102 - val_accuracy: 0.7569\n",
      "Epoch 3/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5140 - accuracy: 0.7520 - val_loss: 0.4907 - val_accuracy: 0.7761\n",
      "Epoch 4/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5090 - accuracy: 0.7568 - val_loss: 0.5037 - val_accuracy: 0.7633\n",
      "Epoch 5/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5073 - accuracy: 0.7584 - val_loss: 0.4863 - val_accuracy: 0.7868\n",
      "Epoch 6/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5085 - accuracy: 0.7520 - val_loss: 0.4845 - val_accuracy: 0.7846\n",
      "Epoch 7/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5046 - accuracy: 0.7621 - val_loss: 0.4888 - val_accuracy: 0.7889\n",
      "Epoch 8/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5056 - accuracy: 0.7552 - val_loss: 0.4788 - val_accuracy: 0.7932\n",
      "Epoch 9/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5012 - accuracy: 0.7600 - val_loss: 0.4787 - val_accuracy: 0.7932\n",
      "Epoch 10/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5011 - accuracy: 0.7648 - val_loss: 0.4938 - val_accuracy: 0.7719\n",
      "Epoch 11/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5015 - accuracy: 0.7627 - val_loss: 0.4759 - val_accuracy: 0.7974\n",
      "Epoch 12/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4985 - accuracy: 0.7717 - val_loss: 0.4823 - val_accuracy: 0.7846\n",
      "Epoch 13/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4994 - accuracy: 0.7600 - val_loss: 0.4755 - val_accuracy: 0.7953\n",
      "Epoch 14/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4988 - accuracy: 0.7568 - val_loss: 0.4740 - val_accuracy: 0.7953\n",
      "Epoch 15/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4960 - accuracy: 0.7691 - val_loss: 0.4734 - val_accuracy: 0.7996\n",
      "Epoch 16/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4975 - accuracy: 0.7643 - val_loss: 0.4743 - val_accuracy: 0.8017\n",
      "Epoch 17/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4966 - accuracy: 0.7627 - val_loss: 0.4756 - val_accuracy: 0.7825\n",
      "Epoch 18/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4964 - accuracy: 0.7621 - val_loss: 0.4832 - val_accuracy: 0.7804\n",
      "Epoch 19/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4942 - accuracy: 0.7659 - val_loss: 0.4717 - val_accuracy: 0.8017\n",
      "Epoch 20/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4928 - accuracy: 0.7643 - val_loss: 0.4735 - val_accuracy: 0.7974\n",
      "Epoch 21/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4938 - accuracy: 0.7680 - val_loss: 0.4800 - val_accuracy: 0.7825\n",
      "Epoch 22/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4911 - accuracy: 0.7643 - val_loss: 0.4709 - val_accuracy: 0.7996\n",
      "Epoch 23/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4907 - accuracy: 0.7685 - val_loss: 0.4686 - val_accuracy: 0.8060\n",
      "Epoch 24/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4913 - accuracy: 0.7605 - val_loss: 0.4697 - val_accuracy: 0.8038\n",
      "Epoch 25/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4897 - accuracy: 0.7691 - val_loss: 0.4681 - val_accuracy: 0.7953\n",
      "Epoch 26/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4900 - accuracy: 0.7659 - val_loss: 0.4688 - val_accuracy: 0.8017\n",
      "Epoch 27/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4909 - accuracy: 0.7669 - val_loss: 0.4683 - val_accuracy: 0.8060\n",
      "Epoch 28/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4868 - accuracy: 0.7691 - val_loss: 0.4791 - val_accuracy: 0.7846\n",
      "Epoch 29/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4880 - accuracy: 0.7701 - val_loss: 0.4687 - val_accuracy: 0.8038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4854 - accuracy: 0.7696 - val_loss: 0.4687 - val_accuracy: 0.7974\n",
      "Epoch 31/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4878 - accuracy: 0.7659 - val_loss: 0.4670 - val_accuracy: 0.8017\n",
      "Epoch 32/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4886 - accuracy: 0.7653 - val_loss: 0.4671 - val_accuracy: 0.7974\n",
      "Epoch 33/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4882 - accuracy: 0.7691 - val_loss: 0.4743 - val_accuracy: 0.7889\n",
      "Epoch 34/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4843 - accuracy: 0.7696 - val_loss: 0.4993 - val_accuracy: 0.7655\n",
      "Epoch 35/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4890 - accuracy: 0.7589 - val_loss: 0.4662 - val_accuracy: 0.8060\n",
      "Epoch 36/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4858 - accuracy: 0.7685 - val_loss: 0.4875 - val_accuracy: 0.7740\n",
      "Epoch 37/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4855 - accuracy: 0.7696 - val_loss: 0.4864 - val_accuracy: 0.7804\n",
      "Epoch 38/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4847 - accuracy: 0.7739 - val_loss: 0.4721 - val_accuracy: 0.7910\n",
      "Epoch 39/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4854 - accuracy: 0.7691 - val_loss: 0.4657 - val_accuracy: 0.7974\n",
      "Epoch 40/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4830 - accuracy: 0.7696 - val_loss: 0.4742 - val_accuracy: 0.7889\n",
      "Epoch 41/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4828 - accuracy: 0.7717 - val_loss: 0.4667 - val_accuracy: 0.8017\n",
      "Epoch 42/48\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.4839 - accuracy: 0.7696 - val_loss: 0.4675 - val_accuracy: 0.7953\n",
      "Epoch 43/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4855 - accuracy: 0.7701 - val_loss: 0.4689 - val_accuracy: 0.7910\n",
      "Epoch 44/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4803 - accuracy: 0.7717 - val_loss: 0.4761 - val_accuracy: 0.7868\n",
      "Epoch 45/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4855 - accuracy: 0.7712 - val_loss: 0.4679 - val_accuracy: 0.7996\n",
      "Epoch 46/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4838 - accuracy: 0.7653 - val_loss: 0.4652 - val_accuracy: 0.7953\n",
      "Epoch 47/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4822 - accuracy: 0.7717 - val_loss: 0.4721 - val_accuracy: 0.7889\n",
      "Epoch 48/48\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.4826 - accuracy: 0.7739 - val_loss: 0.4713 - val_accuracy: 0.7910\n",
      "accuracy: 79.10%\n",
      "79.06% (+/- 1.18%)\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "seed = 7\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "cvscores = []\n",
    "for train, test in kfold.split(X, y_sample):\n",
    "  # create model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, activation='relu', input_shape=(1, 6),return_sequences=True))\n",
    "    model.add(LSTM(27, activation='relu'))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    model.fit(x_train,y_train, epochs=48, batch_size=5, validation_data=(x_test, y_test))\n",
    "\n",
    "    # evaluate the mode\n",
    "    scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    cvscores.append(scores[1] * 100)\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (numpy.mean(cvscores), numpy.std(cvscores)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
